{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from itertools import product\n",
    "import pdb\n",
    "import sys\n",
    "from mnist import MNIST\n",
    "# import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('./mnist/python-mnist/data/')\n",
    "    # 载入数据\n",
    "test_data_all, test_label_all = mndata.load_testing()\n",
    "train_data_all, train_label_all = mndata.load_training()\n",
    "\n",
    "test_data_all = torch.tensor(test_data_all).float()\n",
    "train_label_all = torch.tensor(train_label_all)\n",
    "test_label_all = torch.tensor(test_label_all)\n",
    "train_data_all = torch.tensor(train_data_all).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data, test_label = test_data_all[0:20], test_label_all[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = train_data_all[0:100], train_label_all[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化数据，数据预处理一下\n",
    "train_data = train_data / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(image):\n",
    "    feature = image.view(1, 784)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature, w1, w2, b1, b2):\n",
    "#   feature = torch.cat((feature,torch.tensor(1.0).view(1,1)),1)\n",
    "#   print(feature.shape)\n",
    "    # 前向传播\n",
    "    a1 = torch.mm(feature,w1) + b1\n",
    "#     print('a1 ',a1.shape)\n",
    "    z1 = torch.sigmoid(a1.float())\n",
    "#     print('z1 ',z1.shape)\n",
    "#     z1 = torch.cat((z1,torch.tensor(1.0).view(1,1)),1)\n",
    "#     print('z1 ',z1.shape)\n",
    "    a2 = torch.mm(z1, w2) + b2\n",
    "#     print(a2)\n",
    "    y = F.softmax(a2.float(), dim=1)\n",
    "#     print(y)\n",
    "#     y = torch.argmax(y, dim=1)\n",
    "#     print(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-67c693fb80fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'w1' is not defined"
     ]
    }
   ],
   "source": [
    "res = model(train_data[1].view(1,784), w1,w2,b1,b2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2ground_truth(image_label):\n",
    "    gt = torch.ones(10,10)\n",
    "    gt = gt*-1.0\n",
    "    #for label in image_label:\n",
    "    for i in range(0,10):\n",
    "        gt[i,i]=float(image_label[i])\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(gt):\n",
    "    gt_vector = torch.ones(1,10)\n",
    "    gt_vector *= -0.1\n",
    "    gt_vector[0,gt] = 0.9\n",
    "    return gt_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1000,  0.9000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
       "         -0.1000, -0.1000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(train_label[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y,t):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x, t):\n",
    "    y = model(x,w1,w2,b1,b2)\n",
    "    return cross_entropy(y,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(image_data,image_label,w1,w2,b1,b2, start_i,end_i):\n",
    "    correct=0\n",
    "    for i in range(start_i,end_i):\n",
    "             #print(image_label[i])\n",
    "             #y = model(get_feature(image_data[i]),weights)\n",
    "        feature = get_feature(image_data[i])\n",
    "        y = model(feature,w1,w2,b1,b2)\n",
    "             #pdb.set_trace()\n",
    "        gt = image_label[i]\n",
    "             #pred=torch.argmin(torch.abs(y-gt)).item()\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "             #pred = torch.argmin((torch.abs(y-1))).item()\n",
    "             #print(\"图像[%s]得分类结果是:[%s]\"%(gt,pred))\n",
    "        if gt==pred:\n",
    "            correct+=1\n",
    "             \n",
    "    #print(\"acc=%s\"%(float(correct/20.0)))\n",
    "    return  float(correct/float(end_i-start_i))\n",
    "\n",
    "# print(image_train[1])\n",
    "# y1 = predict(image_train[0:10].view(10,784))\n",
    "# print(image_train[0:10].shape)\n",
    "# t = np.argmax(y1.detach().numpy(), axis=0)\n",
    "# print(y1)\n",
    "# print(t)\n",
    "def accuracy(image_data, image_label, w1, b1, w2, b2):\n",
    "    acc = 0\n",
    "    output = predict(image_data, w1, b1, w2, b2)\n",
    "    y = torch.argmax(output, dim=1)\n",
    "    cnt = torch.sum(y == image_label)\n",
    "    acc = cnt.data.item() / image_data.shape[0]\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(image_data, image_label, w1, w2,b1,b2, lr = 0.05):\n",
    "    loss_value_before=1000000000000000.\n",
    "    loss_value=10000000000000.\n",
    "    \n",
    "    for epoch in range(500):\n",
    "        loss_value_before = loss_value\n",
    "        loss_value = 0\n",
    "        for i in range(0,80):\n",
    "            feature = get_feature(image_data[i])\n",
    "            y = model(feature, w1, w2,b1,b2)\n",
    "            gt = image_label[i]\n",
    "            gt_vector = one_hot(gt).float()\n",
    "            \n",
    "#             print(gt_vector)\n",
    "            loss = 0.5 * torch.sum((y-gt_vector).mul(y-gt_vector)).float()\n",
    "#             loss = F.cross_entropy(y, image_label[i:i+1])\n",
    "            loss_value += loss.data.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            w1.data.sub_(w1.grad.data*lr)\n",
    "            w2.data.sub_(w2.grad.data*lr)\n",
    "            b1.data.sub_(b1.grad.data*lr)\n",
    "            b2.data.sub_(b2.grad.data*lr)\n",
    "            w1.grad.data.zero_()\n",
    "            w2.grad.data.zero_()\n",
    "            b1.grad.data.zero_()\n",
    "            b2.grad.data.zero_()\n",
    "            \n",
    "        train_acc = get_acc(image_data, image_label, w1,w2,b1,b2,0,80)\n",
    "        test_acc = get_acc(image_data,image_label,w1,w2,b1,b2,80,100)\n",
    "        print(\"epoch=%s,loss=%s/%s,train/test_acc=%s/%s,\"%(epoch,loss_value,loss_value_before,train_acc,test_acc))\n",
    "    \n",
    "    return w1 ,w2,b1,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0,loss=61.869082406163216/10000000000000.0,train/test_acc=0.175/0.15,\n",
      "epoch=1,loss=56.90801456198096/61.869082406163216,train/test_acc=0.225/0.15,\n",
      "epoch=2,loss=54.26785750314593/56.90801456198096,train/test_acc=0.25/0.25,\n",
      "epoch=3,loss=51.55289439484477/54.26785750314593,train/test_acc=0.2875/0.25,\n",
      "epoch=4,loss=48.25546778738499/51.55289439484477,train/test_acc=0.2875/0.35,\n",
      "epoch=5,loss=46.44975093379617/48.25546778738499,train/test_acc=0.3/0.4,\n",
      "epoch=6,loss=45.03319676220417/46.44975093379617,train/test_acc=0.3125/0.4,\n",
      "epoch=7,loss=43.4773994833231/45.03319676220417,train/test_acc=0.35/0.45,\n",
      "epoch=8,loss=41.52253856882453/43.4773994833231,train/test_acc=0.375/0.4,\n",
      "epoch=9,loss=38.59670163691044/41.52253856882453,train/test_acc=0.4125/0.45,\n",
      "epoch=10,loss=35.87777064740658/38.59670163691044,train/test_acc=0.475/0.45,\n",
      "epoch=11,loss=33.52701535075903/35.87777064740658,train/test_acc=0.5/0.5,\n",
      "epoch=12,loss=31.861690402030945/33.52701535075903,train/test_acc=0.525/0.45,\n",
      "epoch=13,loss=30.359448697417974/31.861690402030945,train/test_acc=0.55/0.45,\n",
      "epoch=14,loss=28.920504365116358/30.359448697417974,train/test_acc=0.5875/0.45,\n",
      "epoch=15,loss=27.612552735954523/28.920504365116358,train/test_acc=0.5875/0.45,\n",
      "epoch=16,loss=26.58635599911213/27.612552735954523,train/test_acc=0.6/0.45,\n",
      "epoch=17,loss=25.7922515720129/26.58635599911213,train/test_acc=0.6/0.45,\n",
      "epoch=18,loss=25.089548129588366/25.7922515720129,train/test_acc=0.6/0.45,\n",
      "epoch=19,loss=24.379064165055752/25.089548129588366,train/test_acc=0.6375/0.45,\n",
      "epoch=20,loss=23.598869267851114/24.379064165055752,train/test_acc=0.675/0.4,\n",
      "epoch=21,loss=22.77456208691001/23.598869267851114,train/test_acc=0.675/0.4,\n",
      "epoch=22,loss=22.035883959382772/22.77456208691001,train/test_acc=0.6875/0.4,\n",
      "epoch=23,loss=21.399932011961937/22.035883959382772,train/test_acc=0.7/0.4,\n",
      "epoch=24,loss=20.846884071826935/21.399932011961937,train/test_acc=0.7125/0.4,\n",
      "epoch=25,loss=20.397219102829695/20.846884071826935,train/test_acc=0.7125/0.4,\n",
      "epoch=26,loss=20.057193133980036/20.397219102829695,train/test_acc=0.7125/0.4,\n",
      "epoch=27,loss=19.798219799995422/20.057193133980036,train/test_acc=0.7125/0.4,\n",
      "epoch=28,loss=19.591722197830677/19.798219799995422,train/test_acc=0.7125/0.4,\n",
      "epoch=29,loss=19.41925874724984/19.591722197830677,train/test_acc=0.7125/0.4,\n",
      "epoch=30,loss=19.26812756806612/19.41925874724984,train/test_acc=0.7125/0.4,\n",
      "epoch=31,loss=19.128418270498514/19.26812756806612,train/test_acc=0.7125/0.4,\n",
      "epoch=32,loss=18.991167444735765/19.128418270498514,train/test_acc=0.7125/0.4,\n",
      "epoch=33,loss=18.846471715718508/18.991167444735765,train/test_acc=0.7125/0.4,\n",
      "epoch=34,loss=18.680812183767557/18.846471715718508,train/test_acc=0.7125/0.4,\n",
      "epoch=35,loss=18.472739171236753/18.680812183767557,train/test_acc=0.725/0.4,\n",
      "epoch=36,loss=18.18960289657116/18.472739171236753,train/test_acc=0.7375/0.45,\n",
      "epoch=37,loss=17.81371247395873/18.18960289657116,train/test_acc=0.7375/0.45,\n",
      "epoch=38,loss=17.413855474442244/17.81371247395873,train/test_acc=0.75/0.45,\n",
      "epoch=39,loss=17.054986961185932/17.413855474442244,train/test_acc=0.7625/0.45,\n",
      "epoch=40,loss=16.729450818151236/17.054986961185932,train/test_acc=0.7625/0.45,\n",
      "epoch=41,loss=16.430740978568792/16.729450818151236,train/test_acc=0.775/0.5,\n",
      "epoch=42,loss=16.164653465151787/16.430740978568792,train/test_acc=0.775/0.5,\n",
      "epoch=43,loss=15.939263265579939/16.164653465151787,train/test_acc=0.775/0.5,\n",
      "epoch=44,loss=15.755091812461615/15.939263265579939,train/test_acc=0.775/0.5,\n",
      "epoch=45,loss=15.609014924615622/15.755091812461615,train/test_acc=0.775/0.5,\n",
      "epoch=46,loss=15.492702901363373/15.609014924615622,train/test_acc=0.775/0.5,\n",
      "epoch=47,loss=15.39570290595293/15.492702901363373,train/test_acc=0.775/0.5,\n",
      "epoch=48,loss=15.309819135814905/15.39570290595293,train/test_acc=0.775/0.5,\n",
      "epoch=49,loss=15.229552511125803/15.309819135814905,train/test_acc=0.775/0.5,\n",
      "epoch=50,loss=15.15116186067462/15.229552511125803,train/test_acc=0.775/0.5,\n",
      "epoch=51,loss=15.071884546428919/15.15116186067462,train/test_acc=0.775/0.5,\n",
      "epoch=52,loss=14.98949222639203/15.071884546428919,train/test_acc=0.775/0.5,\n",
      "epoch=53,loss=14.902034528553486/14.98949222639203,train/test_acc=0.775/0.5,\n",
      "epoch=54,loss=14.807695399969816/14.902034528553486,train/test_acc=0.775/0.5,\n",
      "epoch=55,loss=14.704623736441135/14.807695399969816,train/test_acc=0.8/0.5,\n",
      "epoch=56,loss=14.590640287846327/14.704623736441135,train/test_acc=0.8/0.5,\n",
      "epoch=57,loss=14.46266195178032/14.590640287846327,train/test_acc=0.8/0.5,\n",
      "epoch=58,loss=14.315929681062698/14.46266195178032,train/test_acc=0.8125/0.5,\n",
      "epoch=59,loss=14.144195329397917/14.315929681062698,train/test_acc=0.8125/0.5,\n",
      "epoch=60,loss=13.945677183568478/14.144195329397917,train/test_acc=0.8125/0.5,\n",
      "epoch=61,loss=13.738225102424622/13.945677183568478,train/test_acc=0.825/0.5,\n",
      "epoch=62,loss=13.550787102431059/13.738225102424622,train/test_acc=0.8375/0.5,\n",
      "epoch=63,loss=13.385384660214186/13.550787102431059,train/test_acc=0.8375/0.5,\n",
      "epoch=64,loss=13.230070482939482/13.385384660214186,train/test_acc=0.8375/0.5,\n",
      "epoch=65,loss=13.079344138503075/13.230070482939482,train/test_acc=0.8375/0.5,\n",
      "epoch=66,loss=12.933743000030518/13.079344138503075,train/test_acc=0.8375/0.5,\n",
      "epoch=67,loss=12.796430181711912/12.933743000030518,train/test_acc=0.8375/0.5,\n",
      "epoch=68,loss=12.670175716280937/12.796430181711912,train/test_acc=0.8375/0.5,\n",
      "epoch=69,loss=12.555420611053705/12.670175716280937,train/test_acc=0.8375/0.55,\n",
      "epoch=70,loss=12.450225681066513/12.555420611053705,train/test_acc=0.8375/0.55,\n",
      "epoch=71,loss=12.35136053711176/12.450225681066513,train/test_acc=0.8375/0.55,\n",
      "epoch=72,loss=12.255445156246424/12.35136053711176,train/test_acc=0.85/0.55,\n",
      "epoch=73,loss=12.159976076334715/12.255445156246424,train/test_acc=0.85/0.55,\n",
      "epoch=74,loss=12.064501218497753/12.159976076334715,train/test_acc=0.85/0.55,\n",
      "epoch=75,loss=11.971423704177141/12.064501218497753,train/test_acc=0.85/0.55,\n",
      "epoch=76,loss=11.884972982108593/11.971423704177141,train/test_acc=0.85/0.55,\n",
      "epoch=77,loss=11.808411836624146/11.884972982108593,train/test_acc=0.85/0.55,\n",
      "epoch=78,loss=11.742327097803354/11.808411836624146,train/test_acc=0.85/0.55,\n",
      "epoch=79,loss=11.68535951897502/11.742327097803354,train/test_acc=0.85/0.55,\n",
      "epoch=80,loss=11.635643113404512/11.68535951897502,train/test_acc=0.85/0.55,\n",
      "epoch=81,loss=11.591523617506027/11.635643113404512,train/test_acc=0.85/0.55,\n",
      "epoch=82,loss=11.551706910133362/11.591523617506027,train/test_acc=0.85/0.55,\n",
      "epoch=83,loss=11.515192411839962/11.551706910133362,train/test_acc=0.85/0.55,\n",
      "epoch=84,loss=11.48119056597352/11.515192411839962,train/test_acc=0.85/0.55,\n",
      "epoch=85,loss=11.449057191610336/11.48119056597352,train/test_acc=0.85/0.55,\n",
      "epoch=86,loss=11.418247256428003/11.449057191610336,train/test_acc=0.85/0.55,\n",
      "epoch=87,loss=11.388286098837852/11.418247256428003,train/test_acc=0.85/0.55,\n",
      "epoch=88,loss=11.35874530300498/11.388286098837852,train/test_acc=0.85/0.55,\n",
      "epoch=89,loss=11.329227592796087/11.35874530300498,train/test_acc=0.85/0.55,\n",
      "epoch=90,loss=11.299357958137989/11.329227592796087,train/test_acc=0.85/0.55,\n",
      "epoch=91,loss=11.268778584897518/11.299357958137989,train/test_acc=0.85/0.55,\n",
      "epoch=92,loss=11.237148620188236/11.268778584897518,train/test_acc=0.85/0.55,\n",
      "epoch=93,loss=11.204152829945087/11.237148620188236,train/test_acc=0.85/0.55,\n",
      "epoch=94,loss=11.169514499604702/11.204152829945087,train/test_acc=0.8625/0.55,\n",
      "epoch=95,loss=11.133011132478714/11.169514499604702,train/test_acc=0.8625/0.55,\n",
      "epoch=96,loss=11.094499852508307/11.133011132478714,train/test_acc=0.8625/0.55,\n",
      "epoch=97,loss=11.053925510495901/11.094499852508307,train/test_acc=0.8625/0.55,\n",
      "epoch=98,loss=11.011320523917675/11.053925510495901,train/test_acc=0.8625/0.55,\n",
      "epoch=99,loss=10.966776762157679/11.011320523917675,train/test_acc=0.8625/0.55,\n",
      "epoch=100,loss=10.920390382409096/10.966776762157679,train/test_acc=0.8625/0.55,\n",
      "epoch=101,loss=10.872195549309254/10.920390382409096,train/test_acc=0.8625/0.55,\n",
      "epoch=102,loss=10.822101671248674/10.872195549309254,train/test_acc=0.8625/0.55,\n",
      "epoch=103,loss=10.769866541028023/10.822101671248674,train/test_acc=0.8625/0.55,\n",
      "epoch=104,loss=10.71510710194707/10.769866541028023,train/test_acc=0.8625/0.55,\n",
      "epoch=105,loss=10.657349981367588/10.71510710194707,train/test_acc=0.8625/0.55,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=106,loss=10.5960896871984/10.657349981367588,train/test_acc=0.875/0.55,\n",
      "epoch=107,loss=10.530829399824142/10.5960896871984,train/test_acc=0.875/0.55,\n",
      "epoch=108,loss=10.46110600978136/10.530829399824142,train/test_acc=0.875/0.55,\n",
      "epoch=109,loss=10.386524379253387/10.46110600978136,train/test_acc=0.875/0.55,\n",
      "epoch=110,loss=10.306819930672646/10.386524379253387,train/test_acc=0.875/0.55,\n",
      "epoch=111,loss=10.221930585801601/10.306819930672646,train/test_acc=0.8875/0.55,\n",
      "epoch=112,loss=10.132050797343254/10.221930585801601,train/test_acc=0.8875/0.55,\n",
      "epoch=113,loss=10.03764121234417/10.132050797343254,train/test_acc=0.8875/0.55,\n",
      "epoch=114,loss=9.939371198415756/10.03764121234417,train/test_acc=0.8875/0.55,\n",
      "epoch=115,loss=9.837966792285442/9.939371198415756,train/test_acc=0.8875/0.55,\n",
      "epoch=116,loss=9.734003227204084/9.837966792285442,train/test_acc=0.8875/0.55,\n",
      "epoch=117,loss=9.627736665308475/9.734003227204084,train/test_acc=0.9/0.55,\n",
      "epoch=118,loss=9.519068405032158/9.627736665308475,train/test_acc=0.9/0.55,\n",
      "epoch=119,loss=9.40774255245924/9.519068405032158,train/test_acc=0.9/0.55,\n",
      "epoch=120,loss=9.293955080211163/9.40774255245924,train/test_acc=0.9/0.55,\n",
      "epoch=121,loss=9.178817354142666/9.293955080211163,train/test_acc=0.9125/0.55,\n",
      "epoch=122,loss=9.063717193901539/9.178817354142666,train/test_acc=0.9125/0.55,\n",
      "epoch=123,loss=8.949259672313929/9.063717193901539,train/test_acc=0.925/0.55,\n",
      "epoch=124,loss=8.835372783243656/8.949259672313929,train/test_acc=0.925/0.55,\n",
      "epoch=125,loss=8.722492765635252/8.835372783243656,train/test_acc=0.925/0.55,\n",
      "epoch=126,loss=8.612594425678253/8.722492765635252,train/test_acc=0.925/0.55,\n",
      "epoch=127,loss=8.508953411132097/8.612594425678253,train/test_acc=0.925/0.55,\n",
      "epoch=128,loss=8.414641462266445/8.508953411132097,train/test_acc=0.925/0.55,\n",
      "epoch=129,loss=8.33116939663887/8.414641462266445,train/test_acc=0.925/0.6,\n",
      "epoch=130,loss=8.258418068289757/8.33116939663887,train/test_acc=0.925/0.65,\n",
      "epoch=131,loss=8.195328399538994/8.258418068289757,train/test_acc=0.925/0.65,\n",
      "epoch=132,loss=8.140501387417316/8.195328399538994,train/test_acc=0.925/0.65,\n",
      "epoch=133,loss=8.092519722878933/8.140501387417316,train/test_acc=0.925/0.65,\n",
      "epoch=134,loss=8.050088807940483/8.092519722878933,train/test_acc=0.925/0.65,\n",
      "epoch=135,loss=8.012085136026144/8.050088807940483,train/test_acc=0.925/0.65,\n",
      "epoch=136,loss=7.977551121264696/8.012085136026144,train/test_acc=0.925/0.65,\n",
      "epoch=137,loss=7.945656545460224/7.977551121264696,train/test_acc=0.925/0.65,\n",
      "epoch=138,loss=7.9156464189291/7.945656545460224,train/test_acc=0.925/0.65,\n",
      "epoch=139,loss=7.886782426387072/7.9156464189291,train/test_acc=0.925/0.65,\n",
      "epoch=140,loss=7.858253687620163/7.886782426387072,train/test_acc=0.925/0.65,\n",
      "epoch=141,loss=7.829053107649088/7.858253687620163,train/test_acc=0.925/0.65,\n",
      "epoch=142,loss=7.797768320888281/7.829053107649088,train/test_acc=0.925/0.65,\n",
      "epoch=143,loss=7.76218668743968/7.797768320888281,train/test_acc=0.925/0.65,\n",
      "epoch=144,loss=7.718565296381712/7.76218668743968,train/test_acc=0.925/0.65,\n",
      "epoch=145,loss=7.66032911837101/7.718565296381712,train/test_acc=0.925/0.7,\n",
      "epoch=146,loss=7.57651549205184/7.66032911837101,train/test_acc=0.925/0.65,\n",
      "epoch=147,loss=7.453515086323023/7.57651549205184,train/test_acc=0.95/0.65,\n",
      "epoch=148,loss=7.290580585598946/7.453515086323023,train/test_acc=0.95/0.65,\n",
      "epoch=149,loss=7.124426603317261/7.290580585598946,train/test_acc=0.95/0.65,\n",
      "epoch=150,loss=6.998275883495808/7.124426603317261,train/test_acc=0.95/0.65,\n",
      "epoch=151,loss=6.90943194180727/6.998275883495808,train/test_acc=0.95/0.65,\n",
      "epoch=152,loss=6.842547554522753/6.90943194180727,train/test_acc=0.95/0.65,\n",
      "epoch=153,loss=6.789210624992847/6.842547554522753,train/test_acc=0.95/0.65,\n",
      "epoch=154,loss=6.744866713881493/6.789210624992847,train/test_acc=0.95/0.65,\n",
      "epoch=155,loss=6.706718243658543/6.744866713881493,train/test_acc=0.95/0.65,\n",
      "epoch=156,loss=6.672868460416794/6.706718243658543,train/test_acc=0.95/0.65,\n",
      "epoch=157,loss=6.641905337572098/6.672868460416794,train/test_acc=0.95/0.65,\n",
      "epoch=158,loss=6.61264343559742/6.641905337572098,train/test_acc=0.95/0.65,\n",
      "epoch=159,loss=6.583931043744087/6.61264343559742,train/test_acc=0.95/0.65,\n",
      "epoch=160,loss=6.554426599293947/6.583931043744087,train/test_acc=0.95/0.65,\n",
      "epoch=161,loss=6.522273767739534/6.554426599293947,train/test_acc=0.95/0.65,\n",
      "epoch=162,loss=6.48452864959836/6.522273767739534,train/test_acc=0.95/0.65,\n",
      "epoch=163,loss=6.436234205961227/6.48452864959836,train/test_acc=0.9625/0.65,\n",
      "epoch=164,loss=6.369782872498035/6.436234205961227,train/test_acc=0.9625/0.65,\n",
      "epoch=165,loss=6.279526446014643/6.369782872498035,train/test_acc=0.9625/0.65,\n",
      "epoch=166,loss=6.180125921964645/6.279526446014643,train/test_acc=0.9625/0.65,\n",
      "epoch=167,loss=6.102454748004675/6.180125921964645,train/test_acc=0.9625/0.65,\n",
      "epoch=168,loss=6.049375839531422/6.102454748004675,train/test_acc=0.9625/0.65,\n",
      "epoch=169,loss=6.009609147906303/6.049375839531422,train/test_acc=0.9625/0.65,\n",
      "epoch=170,loss=5.976694211363792/6.009609147906303,train/test_acc=0.9625/0.65,\n",
      "epoch=171,loss=5.947638496756554/5.976694211363792,train/test_acc=0.9625/0.65,\n",
      "epoch=172,loss=5.920866649597883/5.947638496756554,train/test_acc=0.9625/0.65,\n",
      "epoch=173,loss=5.895422499626875/5.920866649597883,train/test_acc=0.975/0.65,\n",
      "epoch=174,loss=5.870665732771158/5.895422499626875,train/test_acc=0.975/0.65,\n",
      "epoch=175,loss=5.84614796936512/5.870665732771158,train/test_acc=0.975/0.75,\n",
      "epoch=176,loss=5.82156016305089/5.84614796936512,train/test_acc=0.975/0.75,\n",
      "epoch=177,loss=5.796716019511223/5.82156016305089,train/test_acc=0.975/0.75,\n",
      "epoch=178,loss=5.771545983850956/5.796716019511223,train/test_acc=0.975/0.75,\n",
      "epoch=179,loss=5.746100813150406/5.771545983850956,train/test_acc=0.975/0.75,\n",
      "epoch=180,loss=5.720541499555111/5.746100813150406,train/test_acc=0.975/0.75,\n",
      "epoch=181,loss=5.695117529481649/5.720541499555111,train/test_acc=0.975/0.75,\n",
      "epoch=182,loss=5.670130342245102/5.695117529481649,train/test_acc=0.975/0.75,\n",
      "epoch=183,loss=5.645885106176138/5.670130342245102,train/test_acc=0.975/0.75,\n",
      "epoch=184,loss=5.622647058218718/5.645885106176138,train/test_acc=0.975/0.75,\n",
      "epoch=185,loss=5.6006138920784/5.622647058218718,train/test_acc=0.975/0.75,\n",
      "epoch=186,loss=5.579902682453394/5.6006138920784,train/test_acc=0.975/0.75,\n",
      "epoch=187,loss=5.560560245066881/5.579902682453394,train/test_acc=0.975/0.75,\n",
      "epoch=188,loss=5.542574089020491/5.560560245066881,train/test_acc=0.975/0.75,\n",
      "epoch=189,loss=5.525893297046423/5.542574089020491,train/test_acc=0.975/0.75,\n",
      "epoch=190,loss=5.5104424469172955/5.525893297046423,train/test_acc=0.975/0.75,\n",
      "epoch=191,loss=5.496132630854845/5.5104424469172955,train/test_acc=0.975/0.75,\n",
      "epoch=192,loss=5.482872564345598/5.496132630854845,train/test_acc=0.975/0.8,\n",
      "epoch=193,loss=5.47057057544589/5.482872564345598,train/test_acc=0.975/0.8,\n",
      "epoch=194,loss=5.459140080958605/5.47057057544589,train/test_acc=0.975/0.8,\n",
      "epoch=195,loss=5.448500368744135/5.459140080958605,train/test_acc=0.975/0.8,\n",
      "epoch=196,loss=5.438577622175217/5.448500368744135,train/test_acc=0.975/0.8,\n",
      "epoch=197,loss=5.4293040335178375/5.438577622175217,train/test_acc=0.975/0.8,\n",
      "epoch=198,loss=5.4206193797290325/5.4293040335178375,train/test_acc=0.975/0.8,\n",
      "epoch=199,loss=5.412468429654837/5.4206193797290325,train/test_acc=0.975/0.8,\n",
      "epoch=200,loss=5.404802843928337/5.412468429654837,train/test_acc=0.975/0.8,\n",
      "epoch=201,loss=5.3975789323449135/5.404802843928337,train/test_acc=0.975/0.8,\n",
      "epoch=202,loss=5.390756867825985/5.3975789323449135,train/test_acc=0.975/0.8,\n",
      "epoch=203,loss=5.384302601218224/5.390756867825985,train/test_acc=0.975/0.8,\n",
      "epoch=204,loss=5.378183703869581/5.384302601218224,train/test_acc=0.975/0.8,\n",
      "epoch=205,loss=5.37237248942256/5.378183703869581,train/test_acc=0.975/0.8,\n",
      "epoch=206,loss=5.366842981427908/5.37237248942256,train/test_acc=0.975/0.8,\n",
      "epoch=207,loss=5.361572414636612/5.366842981427908,train/test_acc=0.975/0.8,\n",
      "epoch=208,loss=5.356540009379387/5.361572414636612,train/test_acc=0.975/0.8,\n",
      "epoch=209,loss=5.351726498454809/5.356540009379387,train/test_acc=0.975/0.8,\n",
      "epoch=210,loss=5.347115226089954/5.351726498454809,train/test_acc=0.975/0.8,\n",
      "epoch=211,loss=5.342690449208021/5.347115226089954,train/test_acc=0.975/0.8,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=212,loss=5.338437654078007/5.342690449208021,train/test_acc=0.975/0.8,\n",
      "epoch=213,loss=5.334343444555998/5.338437654078007,train/test_acc=0.975/0.8,\n",
      "epoch=214,loss=5.330396220088005/5.334343444555998,train/test_acc=0.975/0.8,\n",
      "epoch=215,loss=5.326584868133068/5.330396220088005,train/test_acc=0.975/0.8,\n",
      "epoch=216,loss=5.322898708283901/5.326584868133068,train/test_acc=0.975/0.8,\n",
      "epoch=217,loss=5.319327630102634/5.322898708283901,train/test_acc=0.975/0.8,\n",
      "epoch=218,loss=5.315863333642483/5.319327630102634,train/test_acc=0.975/0.8,\n",
      "epoch=219,loss=5.312496554106474/5.315863333642483,train/test_acc=0.975/0.8,\n",
      "epoch=220,loss=5.309219777584076/5.312496554106474,train/test_acc=0.975/0.8,\n",
      "epoch=221,loss=5.306024331599474/5.309219777584076,train/test_acc=0.975/0.8,\n",
      "epoch=222,loss=5.302903115749359/5.306024331599474,train/test_acc=0.975/0.8,\n",
      "epoch=223,loss=5.299848940223455/5.302903115749359,train/test_acc=0.975/0.8,\n",
      "epoch=224,loss=5.29685452580452/5.299848940223455,train/test_acc=0.975/0.8,\n",
      "epoch=225,loss=5.2939125671982765/5.29685452580452,train/test_acc=0.975/0.8,\n",
      "epoch=226,loss=5.291016403585672/5.2939125671982765,train/test_acc=0.975/0.8,\n",
      "epoch=227,loss=5.288158096373081/5.291016403585672,train/test_acc=0.975/0.8,\n",
      "epoch=228,loss=5.285330571234226/5.288158096373081,train/test_acc=0.975/0.8,\n",
      "epoch=229,loss=5.282525710761547/5.285330571234226,train/test_acc=0.975/0.8,\n",
      "epoch=230,loss=5.2797357104718685/5.282525710761547,train/test_acc=0.975/0.8,\n",
      "epoch=231,loss=5.2769505605101585/5.2797357104718685,train/test_acc=0.975/0.8,\n",
      "epoch=232,loss=5.27416143938899/5.2769505605101585,train/test_acc=0.975/0.8,\n",
      "epoch=233,loss=5.271357171237469/5.27416143938899,train/test_acc=0.975/0.8,\n",
      "epoch=234,loss=5.268525376915932/5.271357171237469,train/test_acc=0.975/0.8,\n",
      "epoch=235,loss=5.265651993453503/5.268525376915932,train/test_acc=0.975/0.8,\n",
      "epoch=236,loss=5.262721095234156/5.265651993453503,train/test_acc=0.975/0.8,\n",
      "epoch=237,loss=5.259713608771563/5.262721095234156,train/test_acc=0.975/0.85,\n",
      "epoch=238,loss=5.256606820970774/5.259713608771563,train/test_acc=0.975/0.85,\n",
      "epoch=239,loss=5.253373511135578/5.256606820970774,train/test_acc=0.975/0.85,\n",
      "epoch=240,loss=5.2499798983335495/5.253373511135578,train/test_acc=0.975/0.85,\n",
      "epoch=241,loss=5.2463845536112785/5.2499798983335495,train/test_acc=0.975/0.85,\n",
      "epoch=242,loss=5.242535341531038/5.2463845536112785,train/test_acc=0.975/0.85,\n",
      "epoch=243,loss=5.238366179168224/5.242535341531038,train/test_acc=0.975/0.85,\n",
      "epoch=244,loss=5.233790799975395/5.238366179168224,train/test_acc=0.975/0.85,\n",
      "epoch=245,loss=5.228698339313269/5.233790799975395,train/test_acc=0.975/0.85,\n",
      "epoch=246,loss=5.222940672188997/5.228698339313269,train/test_acc=0.975/0.85,\n",
      "epoch=247,loss=5.216320693492889/5.222940672188997,train/test_acc=0.975/0.85,\n",
      "epoch=248,loss=5.20857298001647/5.216320693492889,train/test_acc=0.975/0.85,\n",
      "epoch=249,loss=5.199336655437946/5.20857298001647,train/test_acc=0.975/0.85,\n",
      "epoch=250,loss=5.188124448060989/5.199336655437946,train/test_acc=0.975/0.85,\n",
      "epoch=251,loss=5.174285721033812/5.188124448060989,train/test_acc=0.975/0.85,\n",
      "epoch=252,loss=5.156979613006115/5.174285721033812,train/test_acc=0.975/0.85,\n",
      "epoch=253,loss=5.135200500488281/5.156979613006115,train/test_acc=0.9875/0.85,\n",
      "epoch=254,loss=5.107926186174154/5.135200500488281,train/test_acc=0.9875/0.85,\n",
      "epoch=255,loss=5.074505336582661/5.107926186174154,train/test_acc=0.9875/0.85,\n",
      "epoch=256,loss=5.035312455147505/5.074505336582661,train/test_acc=0.9875/0.85,\n",
      "epoch=257,loss=4.992366127669811/5.035312455147505,train/test_acc=0.9875/0.85,\n",
      "epoch=258,loss=4.949167478829622/4.992366127669811,train/test_acc=0.9875/0.85,\n",
      "epoch=259,loss=4.909391570836306/4.949167478829622,train/test_acc=0.9875/0.85,\n",
      "epoch=260,loss=4.8753420151770115/4.909391570836306,train/test_acc=0.9875/0.85,\n",
      "epoch=261,loss=4.847520671784878/4.8753420151770115,train/test_acc=0.9875/0.85,\n",
      "epoch=262,loss=4.825244780629873/4.847520671784878,train/test_acc=0.9875/0.85,\n",
      "epoch=263,loss=4.807427603751421/4.825244780629873,train/test_acc=0.9875/0.85,\n",
      "epoch=264,loss=4.793027192354202/4.807427603751421,train/test_acc=0.9875/0.85,\n",
      "epoch=265,loss=4.781199421733618/4.793027192354202,train/test_acc=0.9875/0.85,\n",
      "epoch=266,loss=4.771307211369276/4.781199421733618,train/test_acc=0.9875/0.85,\n",
      "epoch=267,loss=4.762883145362139/4.771307211369276,train/test_acc=0.9875/0.85,\n",
      "epoch=268,loss=4.755585994571447/4.762883145362139,train/test_acc=0.9875/0.85,\n",
      "epoch=269,loss=4.749166123569012/4.755585994571447,train/test_acc=0.9875/0.85,\n",
      "epoch=270,loss=4.743437726050615/4.749166123569012,train/test_acc=0.9875/0.85,\n",
      "epoch=271,loss=4.738261226564646/4.743437726050615,train/test_acc=0.9875/0.85,\n",
      "epoch=272,loss=4.733529355376959/4.738261226564646,train/test_acc=0.9875/0.85,\n",
      "epoch=273,loss=4.729157697409391/4.733529355376959,train/test_acc=0.9875/0.85,\n",
      "epoch=274,loss=4.7250793650746346/4.729157697409391,train/test_acc=0.9875/0.85,\n",
      "epoch=275,loss=4.7212384678423405/4.7250793650746346,train/test_acc=0.9875/0.85,\n",
      "epoch=276,loss=4.717588547617197/4.7212384678423405,train/test_acc=0.9875/0.85,\n",
      "epoch=277,loss=4.714088294655085/4.717588547617197,train/test_acc=0.9875/0.85,\n",
      "epoch=278,loss=4.710700284689665/4.714088294655085,train/test_acc=0.9875/0.85,\n",
      "epoch=279,loss=4.707388445734978/4.710700284689665,train/test_acc=0.9875/0.85,\n",
      "epoch=280,loss=4.704116974025965/4.707388445734978,train/test_acc=0.9875/0.85,\n",
      "epoch=281,loss=4.70084835216403/4.704116974025965,train/test_acc=0.9875/0.85,\n",
      "epoch=282,loss=4.697539869695902/4.70084835216403,train/test_acc=0.9875/0.85,\n",
      "epoch=283,loss=4.6941427662968636/4.697539869695902,train/test_acc=0.9875/0.85,\n",
      "epoch=284,loss=4.690596032887697/4.6941427662968636,train/test_acc=0.9875/0.85,\n",
      "epoch=285,loss=4.68682299554348/4.690596032887697,train/test_acc=0.9875/0.85,\n",
      "epoch=286,loss=4.682721812278032/4.68682299554348,train/test_acc=0.9875/0.85,\n",
      "epoch=287,loss=4.678152088075876/4.682721812278032,train/test_acc=0.9875/0.85,\n",
      "epoch=288,loss=4.672915406525135/4.678152088075876,train/test_acc=0.9875/0.85,\n",
      "epoch=289,loss=4.666719704866409/4.672915406525135,train/test_acc=0.9875/0.85,\n",
      "epoch=290,loss=4.659122072160244/4.666719704866409,train/test_acc=0.9875/0.85,\n",
      "epoch=291,loss=4.649424944072962/4.659122072160244,train/test_acc=0.9875/0.85,\n",
      "epoch=292,loss=4.636490978300571/4.649424944072962,train/test_acc=0.9875/0.8,\n",
      "epoch=293,loss=4.618410214781761/4.636490978300571,train/test_acc=0.9875/0.8,\n",
      "epoch=294,loss=4.591952301561832/4.618410214781761,train/test_acc=0.9875/0.8,\n",
      "epoch=295,loss=4.551950074732304/4.591952301561832,train/test_acc=1.0/0.8,\n",
      "epoch=296,loss=4.492134444415569/4.551950074732304,train/test_acc=1.0/0.8,\n",
      "epoch=297,loss=4.412537377327681/4.492134444415569,train/test_acc=1.0/0.8,\n",
      "epoch=298,loss=4.332788344472647/4.412537377327681,train/test_acc=1.0/0.8,\n",
      "epoch=299,loss=4.277038067579269/4.332788344472647,train/test_acc=1.0/0.8,\n",
      "epoch=300,loss=4.243858527392149/4.277038067579269,train/test_acc=1.0/0.8,\n",
      "epoch=301,loss=4.222605671733618/4.243858527392149,train/test_acc=1.0/0.8,\n",
      "epoch=302,loss=4.207329705357552/4.222605671733618,train/test_acc=1.0/0.8,\n",
      "epoch=303,loss=4.195425555109978/4.207329705357552,train/test_acc=1.0/0.8,\n",
      "epoch=304,loss=4.1856699436903/4.195425555109978,train/test_acc=1.0/0.8,\n",
      "epoch=305,loss=4.177413240075111/4.1856699436903,train/test_acc=1.0/0.8,\n",
      "epoch=306,loss=4.170267928391695/4.177413240075111,train/test_acc=1.0/0.8,\n",
      "epoch=307,loss=4.163983762264252/4.170267928391695,train/test_acc=1.0/0.8,\n",
      "epoch=308,loss=4.15838747471571/4.163983762264252,train/test_acc=1.0/0.8,\n",
      "epoch=309,loss=4.15335400775075/4.15838747471571,train/test_acc=1.0/0.8,\n",
      "epoch=310,loss=4.148789197206497/4.15335400775075,train/test_acc=1.0/0.8,\n",
      "epoch=311,loss=4.144621059298515/4.148789197206497,train/test_acc=1.0/0.8,\n",
      "epoch=312,loss=4.140792779624462/4.144621059298515,train/test_acc=1.0/0.8,\n",
      "epoch=313,loss=4.13725833594799/4.140792779624462,train/test_acc=1.0/0.8,\n",
      "epoch=314,loss=4.1339809857308865/4.13725833594799,train/test_acc=1.0/0.8,\n",
      "epoch=315,loss=4.13092964142561/4.1339809857308865,train/test_acc=1.0/0.8,\n",
      "epoch=316,loss=4.128078520298004/4.13092964142561,train/test_acc=1.0/0.8,\n",
      "epoch=317,loss=4.125406712293625/4.128078520298004,train/test_acc=1.0/0.8,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=318,loss=4.122895579785109/4.125406712293625,train/test_acc=1.0/0.8,\n",
      "epoch=319,loss=4.1205292493104935/4.122895579785109,train/test_acc=1.0/0.8,\n",
      "epoch=320,loss=4.118294309824705/4.1205292493104935,train/test_acc=1.0/0.8,\n",
      "epoch=321,loss=4.116178669035435/4.118294309824705,train/test_acc=1.0/0.8,\n",
      "epoch=322,loss=4.114171992987394/4.116178669035435,train/test_acc=1.0/0.8,\n",
      "epoch=323,loss=4.112265400588512/4.114171992987394,train/test_acc=1.0/0.8,\n",
      "epoch=324,loss=4.110450658947229/4.112265400588512,train/test_acc=1.0/0.8,\n",
      "epoch=325,loss=4.108720451593399/4.110450658947229,train/test_acc=1.0/0.8,\n",
      "epoch=326,loss=4.107068549841642/4.108720451593399,train/test_acc=1.0/0.8,\n",
      "epoch=327,loss=4.105489362031221/4.107068549841642,train/test_acc=1.0/0.8,\n",
      "epoch=328,loss=4.10397744551301/4.105489362031221,train/test_acc=1.0/0.8,\n",
      "epoch=329,loss=4.102528419345617/4.10397744551301,train/test_acc=1.0/0.8,\n",
      "epoch=330,loss=4.101137563586235/4.102528419345617,train/test_acc=1.0/0.8,\n",
      "epoch=331,loss=4.099801555275917/4.101137563586235,train/test_acc=1.0/0.8,\n",
      "epoch=332,loss=4.098516430705786/4.099801555275917,train/test_acc=1.0/0.8,\n",
      "epoch=333,loss=4.097279421985149/4.098516430705786,train/test_acc=1.0/0.8,\n",
      "epoch=334,loss=4.0960873663425446/4.097279421985149,train/test_acc=1.0/0.8,\n",
      "epoch=335,loss=4.094937592744827/4.0960873663425446,train/test_acc=1.0/0.8,\n",
      "epoch=336,loss=4.093827605247498/4.094937592744827,train/test_acc=1.0/0.8,\n",
      "epoch=337,loss=4.09275521337986/4.093827605247498,train/test_acc=1.0/0.8,\n",
      "epoch=338,loss=4.091718100011349/4.09275521337986,train/test_acc=1.0/0.8,\n",
      "epoch=339,loss=4.090714503079653/4.091718100011349,train/test_acc=1.0/0.8,\n",
      "epoch=340,loss=4.089742727577686/4.090714503079653,train/test_acc=1.0/0.8,\n",
      "epoch=341,loss=4.088800724595785/4.089742727577686,train/test_acc=1.0/0.8,\n",
      "epoch=342,loss=4.087887454777956/4.088800724595785,train/test_acc=1.0/0.8,\n",
      "epoch=343,loss=4.087000794708729/4.087887454777956,train/test_acc=1.0/0.8,\n",
      "epoch=344,loss=4.08614007756114/4.087000794708729,train/test_acc=1.0/0.8,\n",
      "epoch=345,loss=4.085303511470556/4.08614007756114,train/test_acc=1.0/0.8,\n",
      "epoch=346,loss=4.0844900496304035/4.085303511470556,train/test_acc=1.0/0.8,\n",
      "epoch=347,loss=4.083698932081461/4.0844900496304035,train/test_acc=1.0/0.8,\n",
      "epoch=348,loss=4.082928687334061/4.083698932081461,train/test_acc=1.0/0.8,\n",
      "epoch=349,loss=4.082178629934788/4.082928687334061,train/test_acc=1.0/0.8,\n",
      "epoch=350,loss=4.081447780132294/4.082178629934788,train/test_acc=1.0/0.8,\n",
      "epoch=351,loss=4.080735146999359/4.081447780132294,train/test_acc=1.0/0.8,\n",
      "epoch=352,loss=4.080040190368891/4.080735146999359,train/test_acc=1.0/0.8,\n",
      "epoch=353,loss=4.07936193048954/4.080040190368891,train/test_acc=1.0/0.8,\n",
      "epoch=354,loss=4.078699849545956/4.07936193048954,train/test_acc=1.0/0.8,\n",
      "epoch=355,loss=4.078053008764982/4.078699849545956,train/test_acc=1.0/0.85,\n",
      "epoch=356,loss=4.07742103934288/4.078053008764982,train/test_acc=1.0/0.85,\n",
      "epoch=357,loss=4.076803088188171/4.07742103934288,train/test_acc=1.0/0.85,\n",
      "epoch=358,loss=4.076198987662792/4.076803088188171,train/test_acc=1.0/0.85,\n",
      "epoch=359,loss=4.075607769191265/4.076198987662792,train/test_acc=1.0/0.85,\n",
      "epoch=360,loss=4.075029134750366/4.075607769191265,train/test_acc=1.0/0.85,\n",
      "epoch=361,loss=4.074462927877903/4.075029134750366,train/test_acc=1.0/0.85,\n",
      "epoch=362,loss=4.073908109217882/4.074462927877903,train/test_acc=1.0/0.85,\n",
      "epoch=363,loss=4.0733647383749485/4.073908109217882,train/test_acc=1.0/0.85,\n",
      "epoch=364,loss=4.072832033038139/4.0733647383749485,train/test_acc=1.0/0.85,\n",
      "epoch=365,loss=4.072309907525778/4.072832033038139,train/test_acc=1.0/0.85,\n",
      "epoch=366,loss=4.071797803044319/4.072309907525778,train/test_acc=1.0/0.85,\n",
      "epoch=367,loss=4.071295328438282/4.071797803044319,train/test_acc=1.0/0.85,\n",
      "epoch=368,loss=4.070802453905344/4.071295328438282,train/test_acc=1.0/0.85,\n",
      "epoch=369,loss=4.070318561047316/4.070802453905344,train/test_acc=1.0/0.85,\n",
      "epoch=370,loss=4.069843452423811/4.070318561047316,train/test_acc=1.0/0.85,\n",
      "epoch=371,loss=4.069376826286316/4.069843452423811,train/test_acc=1.0/0.85,\n",
      "epoch=372,loss=4.0689186081290245/4.069376826286316,train/test_acc=1.0/0.85,\n",
      "epoch=373,loss=4.068468276411295/4.0689186081290245,train/test_acc=1.0/0.85,\n",
      "epoch=374,loss=4.0680255480110645/4.068468276411295,train/test_acc=1.0/0.85,\n",
      "epoch=375,loss=4.067590560764074/4.0680255480110645,train/test_acc=1.0/0.85,\n",
      "epoch=376,loss=4.06716251000762/4.067590560764074,train/test_acc=1.0/0.85,\n",
      "epoch=377,loss=4.066741794347763/4.06716251000762,train/test_acc=1.0/0.85,\n",
      "epoch=378,loss=4.066327828913927/4.066741794347763,train/test_acc=1.0/0.85,\n",
      "epoch=379,loss=4.065920542925596/4.066327828913927,train/test_acc=1.0/0.85,\n",
      "epoch=380,loss=4.065519712865353/4.065920542925596,train/test_acc=1.0/0.85,\n",
      "epoch=381,loss=4.0651249922811985/4.065519712865353,train/test_acc=1.0/0.85,\n",
      "epoch=382,loss=4.064736589789391/4.0651249922811985,train/test_acc=1.0/0.85,\n",
      "epoch=383,loss=4.064353927969933/4.064736589789391,train/test_acc=1.0/0.85,\n",
      "epoch=384,loss=4.063977301120758/4.064353927969933,train/test_acc=1.0/0.85,\n",
      "epoch=385,loss=4.063606072217226/4.063977301120758,train/test_acc=1.0/0.85,\n",
      "epoch=386,loss=4.063240390270948/4.063606072217226,train/test_acc=1.0/0.85,\n",
      "epoch=387,loss=4.0628800839185715/4.063240390270948,train/test_acc=1.0/0.85,\n",
      "epoch=388,loss=4.062524929642677/4.0628800839185715,train/test_acc=1.0/0.85,\n",
      "epoch=389,loss=4.062174793332815/4.062524929642677,train/test_acc=1.0/0.85,\n",
      "epoch=390,loss=4.061829581856728/4.062174793332815,train/test_acc=1.0/0.85,\n",
      "epoch=391,loss=4.061489164829254/4.061829581856728,train/test_acc=1.0/0.85,\n",
      "epoch=392,loss=4.061153620481491/4.061489164829254,train/test_acc=1.0/0.85,\n",
      "epoch=393,loss=4.060822527855635/4.061153620481491,train/test_acc=1.0/0.85,\n",
      "epoch=394,loss=4.06049595400691/4.060822527855635,train/test_acc=1.0/0.85,\n",
      "epoch=395,loss=4.060173753648996/4.06049595400691,train/test_acc=1.0/0.85,\n",
      "epoch=396,loss=4.059855632483959/4.060173753648996,train/test_acc=1.0/0.85,\n",
      "epoch=397,loss=4.059541761875153/4.059855632483959,train/test_acc=1.0/0.85,\n",
      "epoch=398,loss=4.059231881052256/4.059541761875153,train/test_acc=1.0/0.85,\n",
      "epoch=399,loss=4.058925993740559/4.059231881052256,train/test_acc=1.0/0.85,\n",
      "epoch=400,loss=4.058624234050512/4.058925993740559,train/test_acc=1.0/0.85,\n",
      "epoch=401,loss=4.058326151221991/4.058624234050512,train/test_acc=1.0/0.85,\n",
      "epoch=402,loss=4.058031640946865/4.058326151221991,train/test_acc=1.0/0.85,\n",
      "epoch=403,loss=4.057740893214941/4.058031640946865,train/test_acc=1.0/0.85,\n",
      "epoch=404,loss=4.05745367333293/4.057740893214941,train/test_acc=1.0/0.85,\n",
      "epoch=405,loss=4.057170003652573/4.05745367333293,train/test_acc=1.0/0.85,\n",
      "epoch=406,loss=4.056889675557613/4.057170003652573,train/test_acc=1.0/0.85,\n",
      "epoch=407,loss=4.056612826883793/4.056889675557613,train/test_acc=1.0/0.85,\n",
      "epoch=408,loss=4.0563389509916306/4.056612826883793,train/test_acc=1.0/0.85,\n",
      "epoch=409,loss=4.056068457663059/4.0563389509916306,train/test_acc=1.0/0.85,\n",
      "epoch=410,loss=4.055801089853048/4.056068457663059,train/test_acc=1.0/0.85,\n",
      "epoch=411,loss=4.055536791682243/4.055801089853048,train/test_acc=1.0/0.85,\n",
      "epoch=412,loss=4.055275395512581/4.055536791682243,train/test_acc=1.0/0.85,\n",
      "epoch=413,loss=4.055017184466124/4.055275395512581,train/test_acc=1.0/0.85,\n",
      "epoch=414,loss=4.054761793464422/4.055017184466124,train/test_acc=1.0/0.85,\n",
      "epoch=415,loss=4.054509062319994/4.054761793464422,train/test_acc=1.0/0.85,\n",
      "epoch=416,loss=4.054259195923805/4.054509062319994,train/test_acc=1.0/0.85,\n",
      "epoch=417,loss=4.054012179374695/4.054259195923805,train/test_acc=1.0/0.85,\n",
      "epoch=418,loss=4.053767796605825/4.054012179374695,train/test_acc=1.0/0.85,\n",
      "epoch=419,loss=4.053526025265455/4.053767796605825,train/test_acc=1.0/0.85,\n",
      "epoch=420,loss=4.0532868802547455/4.053526025265455,train/test_acc=1.0/0.85,\n",
      "epoch=421,loss=4.053050111979246/4.0532868802547455,train/test_acc=1.0/0.85,\n",
      "epoch=422,loss=4.052815955132246/4.053050111979246,train/test_acc=1.0/0.85,\n",
      "epoch=423,loss=4.052584424614906/4.052815955132246,train/test_acc=1.0/0.85,\n",
      "epoch=424,loss=4.052355237305164/4.052584424614906,train/test_acc=1.0/0.85,\n",
      "epoch=425,loss=4.052128203213215/4.052355237305164,train/test_acc=1.0/0.85,\n",
      "epoch=426,loss=4.051903679966927/4.052128203213215,train/test_acc=1.0/0.85,\n",
      "epoch=427,loss=4.051681287586689/4.051903679966927,train/test_acc=1.0/0.85,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=428,loss=4.051461145281792/4.051681287586689,train/test_acc=1.0/0.85,\n",
      "epoch=429,loss=4.051243290305138/4.051461145281792,train/test_acc=1.0/0.85,\n",
      "epoch=430,loss=4.051027599722147/4.051243290305138,train/test_acc=1.0/0.85,\n",
      "epoch=431,loss=4.050814177840948/4.051027599722147,train/test_acc=1.0/0.85,\n",
      "epoch=432,loss=4.050602663308382/4.050814177840948,train/test_acc=1.0/0.85,\n",
      "epoch=433,loss=4.050393242388964/4.050602663308382,train/test_acc=1.0/0.85,\n",
      "epoch=434,loss=4.050185717642307/4.050393242388964,train/test_acc=1.0/0.85,\n",
      "epoch=435,loss=4.049980312585831/4.050185717642307,train/test_acc=1.0/0.85,\n",
      "epoch=436,loss=4.049776904284954/4.049980312585831,train/test_acc=1.0/0.85,\n",
      "epoch=437,loss=4.049575384706259/4.049776904284954,train/test_acc=1.0/0.85,\n",
      "epoch=438,loss=4.049375873059034/4.049575384706259,train/test_acc=1.0/0.85,\n",
      "epoch=439,loss=4.049178052693605/4.049375873059034,train/test_acc=1.0/0.85,\n",
      "epoch=440,loss=4.048982195556164/4.049178052693605,train/test_acc=1.0/0.85,\n",
      "epoch=441,loss=4.0487879775464535/4.048982195556164,train/test_acc=1.0/0.85,\n",
      "epoch=442,loss=4.048595819622278/4.0487879775464535,train/test_acc=1.0/0.85,\n",
      "epoch=443,loss=4.0484052784740925/4.048595819622278,train/test_acc=1.0/0.85,\n",
      "epoch=444,loss=4.048216409981251/4.0484052784740925,train/test_acc=1.0/0.85,\n",
      "epoch=445,loss=4.048029150813818/4.048216409981251,train/test_acc=1.0/0.85,\n",
      "epoch=446,loss=4.047843765467405/4.048029150813818,train/test_acc=1.0/0.85,\n",
      "epoch=447,loss=4.047659877687693/4.047843765467405,train/test_acc=1.0/0.85,\n",
      "epoch=448,loss=4.047477729618549/4.047659877687693,train/test_acc=1.0/0.85,\n",
      "epoch=449,loss=4.047297175973654/4.047477729618549,train/test_acc=1.0/0.85,\n",
      "epoch=450,loss=4.047118108719587/4.047297175973654,train/test_acc=1.0/0.85,\n",
      "epoch=451,loss=4.046940673142672/4.047118108719587,train/test_acc=1.0/0.85,\n",
      "epoch=452,loss=4.046764817088842/4.046940673142672,train/test_acc=1.0/0.85,\n",
      "epoch=453,loss=4.04659042134881/4.046764817088842,train/test_acc=1.0/0.85,\n",
      "epoch=454,loss=4.0464175045490265/4.04659042134881,train/test_acc=1.0/0.85,\n",
      "epoch=455,loss=4.046246036887169/4.0464175045490265,train/test_acc=1.0/0.85,\n",
      "epoch=456,loss=4.04607617482543/4.046246036887169,train/test_acc=1.0/0.85,\n",
      "epoch=457,loss=4.0459075309336185/4.04607617482543,train/test_acc=1.0/0.85,\n",
      "epoch=458,loss=4.045740306377411/4.0459075309336185,train/test_acc=1.0/0.85,\n",
      "epoch=459,loss=4.045574713498354/4.045740306377411,train/test_acc=1.0/0.85,\n",
      "epoch=460,loss=4.0454103499650955/4.045574713498354,train/test_acc=1.0/0.85,\n",
      "epoch=461,loss=4.04524727165699/4.0454103499650955,train/test_acc=1.0/0.85,\n",
      "epoch=462,loss=4.045085668563843/4.04524727165699,train/test_acc=1.0/0.85,\n",
      "epoch=463,loss=4.044925194233656/4.045085668563843,train/test_acc=1.0/0.85,\n",
      "epoch=464,loss=4.0447661355137825/4.044925194233656,train/test_acc=1.0/0.85,\n",
      "epoch=465,loss=4.044608328491449/4.0447661355137825,train/test_acc=1.0/0.85,\n",
      "epoch=466,loss=4.04445182159543/4.044608328491449,train/test_acc=1.0/0.85,\n",
      "epoch=467,loss=4.044296473264694/4.04445182159543,train/test_acc=1.0/0.85,\n",
      "epoch=468,loss=4.0441423915326595/4.044296473264694,train/test_acc=1.0/0.85,\n",
      "epoch=469,loss=4.043989565223455/4.0441423915326595,train/test_acc=1.0/0.85,\n",
      "epoch=470,loss=4.043837830424309/4.043989565223455,train/test_acc=1.0/0.85,\n",
      "epoch=471,loss=4.043687418103218/4.043837830424309,train/test_acc=1.0/0.85,\n",
      "epoch=472,loss=4.043538231402636/4.043687418103218,train/test_acc=1.0/0.85,\n",
      "epoch=473,loss=4.043390158563852/4.043538231402636,train/test_acc=1.0/0.85,\n",
      "epoch=474,loss=4.04324297234416/4.043390158563852,train/test_acc=1.0/0.85,\n",
      "epoch=475,loss=4.043097123503685/4.04324297234416,train/test_acc=1.0/0.85,\n",
      "epoch=476,loss=4.042952422052622/4.043097123503685,train/test_acc=1.0/0.85,\n",
      "epoch=477,loss=4.042808625847101/4.042952422052622,train/test_acc=1.0/0.85,\n",
      "epoch=478,loss=4.042666230350733/4.042808625847101,train/test_acc=1.0/0.85,\n",
      "epoch=479,loss=4.042524579912424/4.042666230350733,train/test_acc=1.0/0.85,\n",
      "epoch=480,loss=4.042384136468172/4.042524579912424,train/test_acc=1.0/0.85,\n",
      "epoch=481,loss=4.0422448962926865/4.042384136468172,train/test_acc=1.0/0.85,\n",
      "epoch=482,loss=4.042106445878744/4.0422448962926865,train/test_acc=1.0/0.85,\n",
      "epoch=483,loss=4.041969139128923/4.042106445878744,train/test_acc=1.0/0.85,\n",
      "epoch=484,loss=4.041832722723484/4.041969139128923,train/test_acc=1.0/0.85,\n",
      "epoch=485,loss=4.041697293519974/4.041832722723484,train/test_acc=1.0/0.85,\n",
      "epoch=486,loss=4.041562903672457/4.041697293519974,train/test_acc=1.0/0.85,\n",
      "epoch=487,loss=4.041429530829191/4.041562903672457,train/test_acc=1.0/0.85,\n",
      "epoch=488,loss=4.041297119110823/4.041429530829191,train/test_acc=1.0/0.85,\n",
      "epoch=489,loss=4.041165612637997/4.041297119110823,train/test_acc=1.0/0.85,\n",
      "epoch=490,loss=4.041035167872906/4.041165612637997,train/test_acc=1.0/0.85,\n",
      "epoch=491,loss=4.040905524045229/4.041035167872906,train/test_acc=1.0/0.85,\n",
      "epoch=492,loss=4.0407767705619335/4.040905524045229,train/test_acc=1.0/0.85,\n",
      "epoch=493,loss=4.04064891859889/4.0407767705619335,train/test_acc=1.0/0.85,\n",
      "epoch=494,loss=4.040522009134293/4.04064891859889,train/test_acc=1.0/0.85,\n",
      "epoch=495,loss=4.040395975112915/4.040522009134293,train/test_acc=1.0/0.85,\n",
      "epoch=496,loss=4.040270783007145/4.040395975112915,train/test_acc=1.0/0.85,\n",
      "epoch=497,loss=4.040146540850401/4.040270783007145,train/test_acc=1.0/0.85,\n",
      "epoch=498,loss=4.040023110806942/4.040146540850401,train/test_acc=1.0/0.85,\n",
      "epoch=499,loss=4.039900474250317/4.040023110806942,train/test_acc=1.0/0.85,\n",
      "acc:  0.97\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    w1 = torch.randn(784, 50, requires_grad=True)\n",
    "    w2 = torch.randn(50, 10, requires_grad=True)\n",
    "    b1 = torch.zeros(1, 50,requires_grad=True)\n",
    "    b2 = torch.zeros(1, 10, requires_grad=True)\n",
    "    \n",
    "    w1, w2, b1, b2 = train_model(train_data, train_label, w1, w2,b1,b2)\n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(0,100):\n",
    "        feature = get_feature(train_data[i])\n",
    "        y = model(feature, w1, w2,b1,b2)\n",
    "        gt = train_label[i]\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        if pred == gt:\n",
    "            correct += 1\n",
    "    \n",
    "    print(\"acc: \", correct / float(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3])\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "res = model(train_data[7].view(1,784), w1,w2,b1,b2)\n",
    "pred = torch.argmax(res, dim=1)\n",
    "print(pred)\n",
    "print(train_label[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndiAJwg4k8b9rUC9l53pqpQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[7].detach().numpy().reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(image_train, train_label, image_test, test_label, w1, w2, b1, b2, lrt=0.01):    \n",
    "#     iter_nums = 1000\n",
    "#     train_size = image_train.shape[0]\n",
    "# #     batch_size = 10\n",
    "\n",
    "#     train_loss_list = []\n",
    "#     train_acc_list = []\n",
    "#     test_acc_list = []\n",
    "    \n",
    "#     one_hot_train = onehot(train_label)\n",
    "#     one_hot_test = onehot(test_label)\n",
    "\n",
    "    \n",
    "#     for i in range(iter_nums):\n",
    "#         loss_last_epoch = 0\n",
    "#         train_acc_epoch = 0\n",
    "#         test_acc_epoch = 0\n",
    "        \n",
    "#         batch_mask = np.random.choice(100, 10)\n",
    "#         train_epoch = image_train[batch_mask]\n",
    "#         label_epoch = one_hot_train[batch_mask]\n",
    "\n",
    "# #         for idx, img in enumerate(image_train):\n",
    "#         y = predict(train_epoch, w1, b1, w2, b2)\n",
    "#     #         print(y)\n",
    "#         loss = torch.sum(0.5 * torch.mul((y - label_epoch), (y - label_epoch)))\n",
    "#         train_loss_list.append(loss)\n",
    "#         print('loss is ',loss.data.item())\n",
    "#             # 反向传播计算梯度\n",
    "#         loss.backward()\n",
    "#         w1.data.sub_(w1.grad.data * lrt)\n",
    "#         w2.data.sub_(w2.grad.data * lrt)\n",
    "#         b1.data.sub_(b1.grad.data * lrt)\n",
    "#         b2.data.sub_(b2.grad.data * lrt)\n",
    "            \n",
    "#         w1.grad.data.zero_()\n",
    "#         b1.grad.data.zero_()\n",
    "#         w2.grad.data.zero_()\n",
    "#         b2.grad.data.zero_()\n",
    "\n",
    "#         train_acc_epoch = accuracy(image_train, train_label, w1, b1, w2, b2)\n",
    "#         test_acc_epoch = accuracy(image_test, test_label, w1, b1, w2, b2)\n",
    "\n",
    "#         train_acc_list.append(train_acc_epoch)\n",
    "#         test_acc_list.append(test_acc_epoch)\n",
    "#         print('train acc, test acc  ' + str(test_acc_epoch) + ', ' + str(test_acc_epoch))\n",
    "# #         print('loss is ', loss_last_epoch / 10)\n",
    "        \n",
    "#     return w1, w2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output1 = predict(image_test, w1,b1,w2,b2)\n",
    "# print(output1)\n",
    "# y = torch.argmax(output1, dim=1)\n",
    "# gt = onehot(test_label)\n",
    "# # print(gt)\n",
    "# # cnt = torch.sum(y == test_label)\n",
    "# # print('cnt = ', cnt )\n",
    "# # print(image_test.shape[0])\n",
    "# # print(cnt.data.item() / image_test.shape[0])\n",
    "# # acc = accuracy(image_test, test_label, w1, b1, w2, b2)\n",
    "# loss = torch.sum(0.5 * (output1 - gt).mul(output1 - gt))\n",
    "# print(loss)\n",
    "# loss.backward()\n",
    "\n",
    "# # print(acc)\n",
    "# # print(loss)\n",
    "# print('w1 grad', sum(w1.grad))\n",
    "# print('shape of grad w1',w1.grad.shape)\n",
    "# print('w1 size',b1.shape)\n",
    "# # print(output1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_AI_CV",
   "language": "python",
   "name": "cv_ml_kr_skl_torch_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
