{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from itertools import product\n",
    "import pdb\n",
    "import sys\n",
    "from mnist import MNIST\n",
    "# import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('./mnist/python-mnist/data/')\n",
    "    # 载入数据\n",
    "test_data_all, test_label_all = mndata.load_testing()\n",
    "train_data_all, train_label_all = mndata.load_training()\n",
    "\n",
    "test_data_all = torch.tensor(test_data_all).float()\n",
    "train_label_all = torch.tensor(train_label_all)\n",
    "test_label_all = torch.tensor(test_label_all)\n",
    "train_data_all = torch.tensor(train_data_all).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data, test_label = test_data_all[0:20], test_label_all[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = train_data_all[0:100], train_label_all[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(image):\n",
    "    feature = image.view(1, 784)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature, w1, w2, b1, b2):\n",
    "#   feature = torch.cat((feature,torch.tensor(1.0).view(1,1)),1)\n",
    "#   print(feature.shape)\n",
    "    # 前向传播\n",
    "    a1 = torch.mm(feature,w1) + b1\n",
    "#     print('a1 ',a1.shape)\n",
    "    z1 = torch.sigmoid(a1.float())\n",
    "#     print('z1 ',z1.shape)\n",
    "#     z1 = torch.cat((z1,torch.tensor(1.0).view(1,1)),1)\n",
    "#     print('z1 ',z1.shape)\n",
    "    a2 = torch.mm(z1, w2) + b2\n",
    "#     print(a2)\n",
    "    y = F.softmax(a2.float(), dim=1)\n",
    "#     print(y)\n",
    "#     y = torch.argmax(y, dim=1)\n",
    "#     print(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3361e-06, 1.3124e-04, 1.8066e-05, 4.6106e-03, 9.4469e-06, 1.3556e-04,\n",
       "         7.9291e-04, 5.0275e-07, 3.2133e-03, 9.9109e-01]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model(train_data[1].view(1,784), w1,w2,b1,b2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2ground_truth(image_label):\n",
    "    gt = torch.ones(10,10)\n",
    "    gt = gt*-1.0\n",
    "    #for label in image_label:\n",
    "    for i in range(0,10):\n",
    "        gt[i,i]=float(image_label[i])\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(gt):\n",
    "    gt_vector = torch.ones(1,10)\n",
    "    gt_vector *= -0.1\n",
    "    gt_vector[0,gt] = 0.9\n",
    "    return gt_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1000,  0.9000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
       "         -0.1000, -0.1000]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(train_label[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y,t):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x, t):\n",
    "    y = model(x,w1,w2,b1,b2)\n",
    "    return cross_entropy(y,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(image_data,image_label,w1,w2,b1,b2, start_i,end_i):\n",
    "    correct=0\n",
    "    for i in range(start_i,end_i):\n",
    "             #print(image_label[i])\n",
    "             #y = model(get_feature(image_data[i]),weights)\n",
    "        feature = get_feature(image_data[i])\n",
    "        y = model(feature,w1,w2,b1,b2)\n",
    "             #pdb.set_trace()\n",
    "        gt = image_label[i]\n",
    "             #pred=torch.argmin(torch.abs(y-gt)).item()\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "             #pred = torch.argmin((torch.abs(y-1))).item()\n",
    "             #print(\"图像[%s]得分类结果是:[%s]\"%(gt,pred))\n",
    "        if gt==pred:\n",
    "            correct+=1\n",
    "             \n",
    "    #print(\"acc=%s\"%(float(correct/20.0)))\n",
    "    return  float(correct/float(end_i-start_i))\n",
    "\n",
    "# print(image_train[1])\n",
    "# y1 = predict(image_train[0:10].view(10,784))\n",
    "# print(image_train[0:10].shape)\n",
    "# t = np.argmax(y1.detach().numpy(), axis=0)\n",
    "# print(y1)\n",
    "# print(t)\n",
    "def accuracy(image_data, image_label, w1, b1, w2, b2):\n",
    "    acc = 0\n",
    "    output = predict(image_data, w1, b1, w2, b2)\n",
    "    y = torch.argmax(output, dim=1)\n",
    "    cnt = torch.sum(y == image_label)\n",
    "    acc = cnt.data.item() / image_data.shape[0]\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(image_data, image_label, w1, w2,b1,b2, lr = 0.1):\n",
    "    loss_value_before=1000000000000000.\n",
    "    loss_value=10000000000000.\n",
    "    \n",
    "    for epoch in range(300):\n",
    "        loss_value_before = loss_value\n",
    "        loss_value = 0\n",
    "        for i in range(0,80):\n",
    "            feature = get_feature(image_data[i])\n",
    "            y = model(feature, w1, w2,b1,b2)\n",
    "            gt = image_label[i]\n",
    "            gt_vector = one_hot(gt).float()\n",
    "            \n",
    "#             print(gt_vector)\n",
    "            loss = 0.5 * torch.sum((y-gt_vector).mul(y-gt_vector)).float()\n",
    "#             loss = F.cross_entropy(y, image_label[i:i+1])\n",
    "            loss_value += loss.data.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            w1.data.sub_(w1.grad.data*lr)\n",
    "            w2.data.sub_(w2.grad.data*lr)\n",
    "            b1.data.sub_(b1.grad.data*lr)\n",
    "            b2.data.sub_(b2.grad.data*lr)\n",
    "            w1.grad.data.zero_()\n",
    "            w2.grad.data.zero_()\n",
    "            b1.grad.data.zero_()\n",
    "            b2.grad.data.zero_()\n",
    "            \n",
    "        train_acc = get_acc(image_data, image_label, w1,w2,b1,b2,0,80)\n",
    "        test_acc = get_acc(image_data,image_label,w1,w2,b1,b2,80,100)\n",
    "        print(\"epoch=%s,loss=%s/%s,train/test_acc=%s/%s,\"%(epoch,loss_value,loss_value_before,train_acc,test_acc))\n",
    "    \n",
    "    return w1 ,w2,b1,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0,loss=65.54742728918791/10000000000000.0,train/test_acc=0.1875/0.25,\n",
      "epoch=1,loss=62.85777333378792/65.54742728918791,train/test_acc=0.175/0.25,\n",
      "epoch=2,loss=60.50642976537347/62.85777333378792,train/test_acc=0.225/0.2,\n",
      "epoch=3,loss=57.45642592385411/60.50642976537347,train/test_acc=0.2875/0.3,\n",
      "epoch=4,loss=55.70289558917284/57.45642592385411,train/test_acc=0.2875/0.2,\n",
      "epoch=5,loss=54.11130578443408/55.70289558917284,train/test_acc=0.2875/0.2,\n",
      "epoch=6,loss=53.541324198246/54.11130578443408,train/test_acc=0.2875/0.2,\n",
      "epoch=7,loss=52.619110606610775/53.541324198246,train/test_acc=0.2875/0.2,\n",
      "epoch=8,loss=51.6578932441771/52.619110606610775,train/test_acc=0.2875/0.25,\n",
      "epoch=9,loss=51.72104113176465/51.6578932441771,train/test_acc=0.3375/0.3,\n",
      "epoch=10,loss=48.552596271038055/51.72104113176465,train/test_acc=0.3375/0.25,\n",
      "epoch=11,loss=49.159980319440365/48.552596271038055,train/test_acc=0.3625/0.35,\n",
      "epoch=12,loss=47.350403387099504/49.159980319440365,train/test_acc=0.375/0.35,\n",
      "epoch=13,loss=46.39899179711938/47.350403387099504,train/test_acc=0.375/0.3,\n",
      "epoch=14,loss=46.145447976887226/46.39899179711938,train/test_acc=0.375/0.3,\n",
      "epoch=15,loss=45.65723633766174/46.145447976887226,train/test_acc=0.375/0.3,\n",
      "epoch=16,loss=44.50335068255663/45.65723633766174,train/test_acc=0.375/0.3,\n",
      "epoch=17,loss=43.90969483926892/44.50335068255663,train/test_acc=0.375/0.3,\n",
      "epoch=18,loss=43.66907123103738/43.90969483926892,train/test_acc=0.375/0.3,\n",
      "epoch=19,loss=42.933096420019865/43.66907123103738,train/test_acc=0.4125/0.3,\n",
      "epoch=20,loss=41.631331734359264/42.933096420019865,train/test_acc=0.4625/0.35,\n",
      "epoch=21,loss=38.425326853990555/41.631331734359264,train/test_acc=0.475/0.3,\n",
      "epoch=22,loss=37.19757055863738/38.425326853990555,train/test_acc=0.4875/0.3,\n",
      "epoch=23,loss=36.04193730279803/37.19757055863738,train/test_acc=0.5/0.3,\n",
      "epoch=24,loss=35.72154234722257/36.04193730279803,train/test_acc=0.5125/0.3,\n",
      "epoch=25,loss=35.02445222809911/35.72154234722257,train/test_acc=0.525/0.35,\n",
      "epoch=26,loss=35.49623143672943/35.02445222809911,train/test_acc=0.5125/0.35,\n",
      "epoch=27,loss=33.97440483048558/35.49623143672943,train/test_acc=0.5375/0.35,\n",
      "epoch=28,loss=33.19546765089035/33.97440483048558,train/test_acc=0.55/0.35,\n",
      "epoch=29,loss=32.3121064119041/33.19546765089035,train/test_acc=0.55/0.4,\n",
      "epoch=30,loss=31.874450601637363/32.3121064119041,train/test_acc=0.55/0.4,\n",
      "epoch=31,loss=31.7604594938457/31.874450601637363,train/test_acc=0.55/0.35,\n",
      "epoch=32,loss=31.58764125406742/31.7604594938457,train/test_acc=0.55/0.35,\n",
      "epoch=33,loss=31.437677830457687/31.58764125406742,train/test_acc=0.55/0.35,\n",
      "epoch=34,loss=31.310372907668352/31.437677830457687,train/test_acc=0.55/0.3,\n",
      "epoch=35,loss=31.1821357794106/31.310372907668352,train/test_acc=0.55/0.3,\n",
      "epoch=36,loss=30.94930701702833/31.1821357794106,train/test_acc=0.55/0.3,\n",
      "epoch=37,loss=30.837807785719633/30.94930701702833,train/test_acc=0.5625/0.3,\n",
      "epoch=38,loss=30.660067405551672/30.837807785719633,train/test_acc=0.5625/0.35,\n",
      "epoch=39,loss=30.169251538813114/30.660067405551672,train/test_acc=0.5625/0.35,\n",
      "epoch=40,loss=29.9137011654675/30.169251538813114,train/test_acc=0.5625/0.4,\n",
      "epoch=41,loss=29.820042174309492/29.9137011654675,train/test_acc=0.5625/0.4,\n",
      "epoch=42,loss=29.745117858052254/29.820042174309492,train/test_acc=0.5625/0.4,\n",
      "epoch=43,loss=29.61877266317606/29.745117858052254,train/test_acc=0.5625/0.4,\n",
      "epoch=44,loss=29.529102817177773/29.61877266317606,train/test_acc=0.5625/0.4,\n",
      "epoch=45,loss=29.47235506400466/29.529102817177773,train/test_acc=0.5625/0.4,\n",
      "epoch=46,loss=29.403801906853914/29.47235506400466,train/test_acc=0.5625/0.4,\n",
      "epoch=47,loss=29.336658969521523/29.403801906853914,train/test_acc=0.5625/0.4,\n",
      "epoch=48,loss=29.261112816631794/29.336658969521523,train/test_acc=0.5625/0.35,\n",
      "epoch=49,loss=29.163807928562164/29.261112816631794,train/test_acc=0.575/0.35,\n",
      "epoch=50,loss=29.03429774194956/29.163807928562164,train/test_acc=0.575/0.35,\n",
      "epoch=51,loss=28.860000502318144/29.03429774194956,train/test_acc=0.575/0.35,\n",
      "epoch=52,loss=28.673635706305504/28.860000502318144,train/test_acc=0.575/0.35,\n",
      "epoch=53,loss=28.520164784044027/28.673635706305504,train/test_acc=0.575/0.35,\n",
      "epoch=54,loss=28.407618932425976/28.520164784044027,train/test_acc=0.575/0.35,\n",
      "epoch=55,loss=28.280154392123222/28.407618932425976,train/test_acc=0.5875/0.35,\n",
      "epoch=56,loss=27.97423454374075/28.280154392123222,train/test_acc=0.6/0.35,\n",
      "epoch=57,loss=27.655543450266123/27.97423454374075,train/test_acc=0.6/0.35,\n",
      "epoch=58,loss=27.39823977649212/27.655543450266123,train/test_acc=0.6/0.45,\n",
      "epoch=59,loss=27.115253247320652/27.39823977649212,train/test_acc=0.6/0.45,\n",
      "epoch=60,loss=26.844014026224613/27.115253247320652,train/test_acc=0.6125/0.45,\n",
      "epoch=61,loss=26.599861152470112/26.844014026224613,train/test_acc=0.6125/0.4,\n",
      "epoch=62,loss=26.355291854590178/26.599861152470112,train/test_acc=0.6125/0.35,\n",
      "epoch=63,loss=26.18817686289549/26.355291854590178,train/test_acc=0.6125/0.35,\n",
      "epoch=64,loss=25.973104629665613/26.18817686289549,train/test_acc=0.625/0.35,\n",
      "epoch=65,loss=25.58628949522972/25.973104629665613,train/test_acc=0.65/0.35,\n",
      "epoch=66,loss=24.589735507965088/25.58628949522972,train/test_acc=0.65/0.35,\n",
      "epoch=67,loss=24.419330272823572/24.589735507965088,train/test_acc=0.65/0.35,\n",
      "epoch=68,loss=24.30494723469019/24.419330272823572,train/test_acc=0.65/0.35,\n",
      "epoch=69,loss=24.24040850251913/24.30494723469019,train/test_acc=0.65/0.35,\n",
      "epoch=70,loss=24.194425217807293/24.24040850251913,train/test_acc=0.65/0.35,\n",
      "epoch=71,loss=24.152737580239773/24.194425217807293,train/test_acc=0.65/0.35,\n",
      "epoch=72,loss=24.11341953277588/24.152737580239773,train/test_acc=0.65/0.35,\n",
      "epoch=73,loss=24.0738426707685/24.11341953277588,train/test_acc=0.65/0.35,\n",
      "epoch=74,loss=24.03051583468914/24.0738426707685,train/test_acc=0.65/0.35,\n",
      "epoch=75,loss=23.977300509810448/24.03051583468914,train/test_acc=0.65/0.35,\n",
      "epoch=76,loss=23.901028268039227/23.977300509810448,train/test_acc=0.6625/0.35,\n",
      "epoch=77,loss=23.63303481414914/23.901028268039227,train/test_acc=0.6625/0.4,\n",
      "epoch=78,loss=23.38843258097768/23.63303481414914,train/test_acc=0.675/0.35,\n",
      "epoch=79,loss=23.204420868307352/23.38843258097768,train/test_acc=0.675/0.35,\n",
      "epoch=80,loss=22.810258202254772/23.204420868307352,train/test_acc=0.675/0.4,\n",
      "epoch=81,loss=22.60971449315548/22.810258202254772,train/test_acc=0.675/0.4,\n",
      "epoch=82,loss=22.42406140640378/22.60971449315548,train/test_acc=0.6875/0.4,\n",
      "epoch=83,loss=22.26928437128663/22.42406140640378,train/test_acc=0.6875/0.35,\n",
      "epoch=84,loss=22.096372708678246/22.26928437128663,train/test_acc=0.6875/0.35,\n",
      "epoch=85,loss=21.946879997849464/22.096372708678246,train/test_acc=0.6875/0.4,\n",
      "epoch=86,loss=21.868853844702244/21.946879997849464,train/test_acc=0.6875/0.4,\n",
      "epoch=87,loss=21.8252841681242/21.868853844702244,train/test_acc=0.6875/0.4,\n",
      "epoch=88,loss=21.80419149622321/21.8252841681242,train/test_acc=0.6875/0.4,\n",
      "epoch=89,loss=21.87241356819868/21.80419149622321,train/test_acc=0.6875/0.4,\n",
      "epoch=90,loss=21.80927975103259/21.87241356819868,train/test_acc=0.6875/0.4,\n",
      "epoch=91,loss=21.78823633119464/21.80927975103259,train/test_acc=0.6875/0.4,\n",
      "epoch=92,loss=21.76318045333028/21.78823633119464,train/test_acc=0.6875/0.4,\n",
      "epoch=93,loss=21.735315904021263/21.76318045333028,train/test_acc=0.6875/0.4,\n",
      "epoch=94,loss=21.711483746767044/21.735315904021263,train/test_acc=0.6875/0.4,\n",
      "epoch=95,loss=21.692027166485786/21.711483746767044,train/test_acc=0.6875/0.4,\n",
      "epoch=96,loss=21.673962622880936/21.692027166485786,train/test_acc=0.6875/0.4,\n",
      "epoch=97,loss=21.65571165457368/21.673962622880936,train/test_acc=0.6875/0.4,\n",
      "epoch=98,loss=21.63675943762064/21.65571165457368,train/test_acc=0.6875/0.4,\n",
      "epoch=99,loss=21.617339722812176/21.63675943762064,train/test_acc=0.6875/0.4,\n",
      "epoch=100,loss=21.598225310444832/21.617339722812176,train/test_acc=0.6875/0.4,\n",
      "epoch=101,loss=21.580370485782623/21.598225310444832,train/test_acc=0.6875/0.4,\n",
      "epoch=102,loss=21.56442793086171/21.580370485782623,train/test_acc=0.6875/0.4,\n",
      "epoch=103,loss=21.55038294196129/21.56442793086171,train/test_acc=0.6875/0.4,\n",
      "epoch=104,loss=21.537659153342247/21.55038294196129,train/test_acc=0.6875/0.4,\n",
      "epoch=105,loss=21.525530602782965/21.537659153342247,train/test_acc=0.6875/0.4,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=106,loss=21.513385709375143/21.525530602782965,train/test_acc=0.6875/0.4,\n",
      "epoch=107,loss=21.500705629587173/21.513385709375143,train/test_acc=0.6875/0.4,\n",
      "epoch=108,loss=21.486928779631853/21.500705629587173,train/test_acc=0.6875/0.4,\n",
      "epoch=109,loss=21.47129399701953/21.486928779631853,train/test_acc=0.6875/0.45,\n",
      "epoch=110,loss=21.452614787966013/21.47129399701953,train/test_acc=0.6875/0.45,\n",
      "epoch=111,loss=21.428780775517225/21.452614787966013,train/test_acc=0.6875/0.45,\n",
      "epoch=112,loss=21.395729511976242/21.428780775517225,train/test_acc=0.6875/0.45,\n",
      "epoch=113,loss=21.348077457398176/21.395729511976242,train/test_acc=0.6875/0.45,\n",
      "epoch=114,loss=21.29241805523634/21.348077457398176,train/test_acc=0.6875/0.45,\n",
      "epoch=115,loss=21.256402496248484/21.29241805523634,train/test_acc=0.6875/0.45,\n",
      "epoch=116,loss=21.243817444890738/21.256402496248484,train/test_acc=0.6875/0.45,\n",
      "epoch=117,loss=21.235780850052834/21.243817444890738,train/test_acc=0.6875/0.45,\n",
      "epoch=118,loss=21.226551838219166/21.235780850052834,train/test_acc=0.6875/0.45,\n",
      "epoch=119,loss=21.21694740653038/21.226551838219166,train/test_acc=0.6875/0.45,\n",
      "epoch=120,loss=21.207838892936707/21.21694740653038,train/test_acc=0.6875/0.45,\n",
      "epoch=121,loss=21.19918417185545/21.207838892936707,train/test_acc=0.6875/0.45,\n",
      "epoch=122,loss=21.190423529595137/21.19918417185545,train/test_acc=0.6875/0.45,\n",
      "epoch=123,loss=21.18103689327836/21.190423529595137,train/test_acc=0.6875/0.45,\n",
      "epoch=124,loss=21.170747984200716/21.18103689327836,train/test_acc=0.6875/0.45,\n",
      "epoch=125,loss=21.159524004906416/21.170747984200716,train/test_acc=0.6875/0.45,\n",
      "epoch=126,loss=21.147545468062162/21.159524004906416,train/test_acc=0.6875/0.45,\n",
      "epoch=127,loss=21.135195087641478/21.147545468062162,train/test_acc=0.6875/0.45,\n",
      "epoch=128,loss=21.1229643933475/21.135195087641478,train/test_acc=0.6875/0.45,\n",
      "epoch=129,loss=21.11124014481902/21.1229643933475,train/test_acc=0.6875/0.45,\n",
      "epoch=130,loss=21.1000730805099/21.11124014481902,train/test_acc=0.6875/0.45,\n",
      "epoch=131,loss=21.08917983621359/21.1000730805099,train/test_acc=0.6875/0.45,\n",
      "epoch=132,loss=21.07818514853716/21.08917983621359,train/test_acc=0.6875/0.45,\n",
      "epoch=133,loss=21.066854532808065/21.07818514853716,train/test_acc=0.6875/0.45,\n",
      "epoch=134,loss=21.055174876004457/21.066854532808065,train/test_acc=0.6875/0.45,\n",
      "epoch=135,loss=21.043383363634348/21.055174876004457,train/test_acc=0.6875/0.45,\n",
      "epoch=136,loss=21.032053902745247/21.043383363634348,train/test_acc=0.6875/0.45,\n",
      "epoch=137,loss=21.022144597023726/21.032053902745247,train/test_acc=0.6875/0.45,\n",
      "epoch=138,loss=21.014623817056417/21.022144597023726,train/test_acc=0.6875/0.45,\n",
      "epoch=139,loss=21.00972505658865/21.014623817056417,train/test_acc=0.6875/0.45,\n",
      "epoch=140,loss=21.006777103990316/21.00972505658865,train/test_acc=0.6875/0.45,\n",
      "epoch=141,loss=21.004865553230047/21.006777103990316,train/test_acc=0.6875/0.45,\n",
      "epoch=142,loss=21.003387674689293/21.004865553230047,train/test_acc=0.6875/0.45,\n",
      "epoch=143,loss=21.002071369439363/21.003387674689293,train/test_acc=0.6875/0.45,\n",
      "epoch=144,loss=21.000814333558083/21.002071369439363,train/test_acc=0.6875/0.45,\n",
      "epoch=145,loss=20.999575950205326/21.000814333558083,train/test_acc=0.6875/0.45,\n",
      "epoch=146,loss=20.99833371862769/20.999575950205326,train/test_acc=0.6875/0.45,\n",
      "epoch=147,loss=20.99707243219018/20.99833371862769,train/test_acc=0.6875/0.45,\n",
      "epoch=148,loss=20.99578022956848/20.99707243219018,train/test_acc=0.6875/0.45,\n",
      "epoch=149,loss=20.99444555863738/20.99578022956848,train/test_acc=0.6875/0.45,\n",
      "epoch=150,loss=20.99305982887745/20.99444555863738,train/test_acc=0.6875/0.45,\n",
      "epoch=151,loss=20.991615131497383/20.99305982887745,train/test_acc=0.6875/0.45,\n",
      "epoch=152,loss=20.99010556563735/20.991615131497383,train/test_acc=0.6875/0.45,\n",
      "epoch=153,loss=20.988525226712227/20.99010556563735,train/test_acc=0.6875/0.45,\n",
      "epoch=154,loss=20.98687221109867/20.988525226712227,train/test_acc=0.6875/0.45,\n",
      "epoch=155,loss=20.985146790742874/20.98687221109867,train/test_acc=0.6875/0.45,\n",
      "epoch=156,loss=20.983351577073336/20.985146790742874,train/test_acc=0.6875/0.45,\n",
      "epoch=157,loss=20.981495786458254/20.983351577073336,train/test_acc=0.6875/0.45,\n",
      "epoch=158,loss=20.979593131691217/20.981495786458254,train/test_acc=0.6875/0.45,\n",
      "epoch=159,loss=20.97766315191984/20.979593131691217,train/test_acc=0.6875/0.45,\n",
      "epoch=160,loss=20.975731413811445/20.97766315191984,train/test_acc=0.6875/0.45,\n",
      "epoch=161,loss=20.973828323185444/20.975731413811445,train/test_acc=0.6875/0.45,\n",
      "epoch=162,loss=20.971987042576075/20.973828323185444,train/test_acc=0.6875/0.45,\n",
      "epoch=163,loss=20.970241244882345/20.971987042576075,train/test_acc=0.6875/0.45,\n",
      "epoch=164,loss=20.968617256730795/20.970241244882345,train/test_acc=0.6875/0.45,\n",
      "epoch=165,loss=20.96713398396969/20.968617256730795,train/test_acc=0.6875/0.45,\n",
      "epoch=166,loss=20.965798780322075/20.96713398396969,train/test_acc=0.6875/0.45,\n",
      "epoch=167,loss=20.964606009423733/20.965798780322075,train/test_acc=0.6875/0.45,\n",
      "epoch=168,loss=20.96354202181101/20.964606009423733,train/test_acc=0.6875/0.45,\n",
      "epoch=169,loss=20.962586697191/20.96354202181101,train/test_acc=0.6875/0.45,\n",
      "epoch=170,loss=20.961714506149292/20.962586697191,train/test_acc=0.6875/0.45,\n",
      "epoch=171,loss=20.960903517901897/20.961714506149292,train/test_acc=0.6875/0.45,\n",
      "epoch=172,loss=20.960132602602243/20.960903517901897,train/test_acc=0.6875/0.45,\n",
      "epoch=173,loss=20.959385607391596/20.960132602602243,train/test_acc=0.6875/0.45,\n",
      "epoch=174,loss=20.95864775776863/20.959385607391596,train/test_acc=0.6875/0.45,\n",
      "epoch=175,loss=20.957908038049936/20.95864775776863,train/test_acc=0.6875/0.45,\n",
      "epoch=176,loss=20.95715943351388/20.957908038049936,train/test_acc=0.6875/0.45,\n",
      "epoch=177,loss=20.95639443024993/20.95715943351388,train/test_acc=0.6875/0.45,\n",
      "epoch=178,loss=20.955606807023287/20.95639443024993,train/test_acc=0.6875/0.45,\n",
      "epoch=179,loss=20.954793453216553/20.955606807023287,train/test_acc=0.6875/0.45,\n",
      "epoch=180,loss=20.953950244933367/20.954793453216553,train/test_acc=0.6875/0.45,\n",
      "epoch=181,loss=20.95307393372059/20.953950244933367,train/test_acc=0.6875/0.45,\n",
      "epoch=182,loss=20.95216243341565/20.95307393372059,train/test_acc=0.6875/0.45,\n",
      "epoch=183,loss=20.951214879751205/20.95216243341565,train/test_acc=0.6875/0.45,\n",
      "epoch=184,loss=20.950228683650494/20.951214879751205,train/test_acc=0.6875/0.45,\n",
      "epoch=185,loss=20.949205167591572/20.950228683650494,train/test_acc=0.6875/0.45,\n",
      "epoch=186,loss=20.948145385831594/20.949205167591572,train/test_acc=0.6875/0.45,\n",
      "epoch=187,loss=20.947052121162415/20.948145385831594,train/test_acc=0.6875/0.45,\n",
      "epoch=188,loss=20.94593008607626/20.947052121162415,train/test_acc=0.6875/0.45,\n",
      "epoch=189,loss=20.944785594940186/20.94593008607626,train/test_acc=0.6875/0.45,\n",
      "epoch=190,loss=20.943628039211035/20.944785594940186,train/test_acc=0.6875/0.45,\n",
      "epoch=191,loss=20.94246841967106/20.943628039211035,train/test_acc=0.6875/0.45,\n",
      "epoch=192,loss=20.941317420452833/20.94246841967106,train/test_acc=0.6875/0.45,\n",
      "epoch=193,loss=20.940189108252525/20.941317420452833,train/test_acc=0.6875/0.45,\n",
      "epoch=194,loss=20.939097490161657/20.940189108252525,train/test_acc=0.6875/0.45,\n",
      "epoch=195,loss=20.93805155158043/20.939097490161657,train/test_acc=0.6875/0.45,\n",
      "epoch=196,loss=20.93706227838993/20.93805155158043,train/test_acc=0.6875/0.45,\n",
      "epoch=197,loss=20.936133831739426/20.93706227838993,train/test_acc=0.6875/0.45,\n",
      "epoch=198,loss=20.93526755273342/20.936133831739426,train/test_acc=0.6875/0.45,\n",
      "epoch=199,loss=20.93446149304509/20.93526755273342,train/test_acc=0.6875/0.45,\n",
      "epoch=200,loss=20.93370994925499/20.93446149304509,train/test_acc=0.6875/0.45,\n",
      "epoch=201,loss=20.93300587683916/20.93370994925499,train/test_acc=0.6875/0.45,\n",
      "epoch=202,loss=20.932340070605278/20.93300587683916,train/test_acc=0.6875/0.45,\n",
      "epoch=203,loss=20.931705500930548/20.932340070605278,train/test_acc=0.6875/0.45,\n",
      "epoch=204,loss=20.931092277169228/20.931705500930548,train/test_acc=0.6875/0.45,\n",
      "epoch=205,loss=20.930493969470263/20.931092277169228,train/test_acc=0.6875/0.45,\n",
      "epoch=206,loss=20.929903343319893/20.930493969470263,train/test_acc=0.6875/0.45,\n",
      "epoch=207,loss=20.929316084831953/20.929903343319893,train/test_acc=0.6875/0.45,\n",
      "epoch=208,loss=20.928726442158222/20.929316084831953,train/test_acc=0.6875/0.45,\n",
      "epoch=209,loss=20.92813178524375/20.928726442158222,train/test_acc=0.6875/0.45,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=210,loss=20.927526645362377/20.92813178524375,train/test_acc=0.6875/0.45,\n",
      "epoch=211,loss=20.92691035196185/20.927526645362377,train/test_acc=0.6875/0.45,\n",
      "epoch=212,loss=20.926278214901686/20.92691035196185,train/test_acc=0.6875/0.45,\n",
      "epoch=213,loss=20.9256294593215/20.926278214901686,train/test_acc=0.6875/0.5,\n",
      "epoch=214,loss=20.92496069893241/20.9256294593215,train/test_acc=0.6875/0.5,\n",
      "epoch=215,loss=20.924270294606686/20.92496069893241,train/test_acc=0.6875/0.5,\n",
      "epoch=216,loss=20.92355601489544/20.924270294606686,train/test_acc=0.6875/0.5,\n",
      "epoch=217,loss=20.922814778983593/20.92355601489544,train/test_acc=0.6875/0.5,\n",
      "epoch=218,loss=20.92204586789012/20.922814778983593,train/test_acc=0.6875/0.5,\n",
      "epoch=219,loss=20.92124581709504/20.92204586789012,train/test_acc=0.6875/0.5,\n",
      "epoch=220,loss=20.920411586761475/20.92124581709504,train/test_acc=0.6875/0.5,\n",
      "epoch=221,loss=20.919542215764523/20.920411586761475,train/test_acc=0.6875/0.5,\n",
      "epoch=222,loss=20.918632365763187/20.919542215764523,train/test_acc=0.6875/0.5,\n",
      "epoch=223,loss=20.917679626494646/20.918632365763187,train/test_acc=0.6875/0.5,\n",
      "epoch=224,loss=20.91668191179633/20.917679626494646,train/test_acc=0.6875/0.5,\n",
      "epoch=225,loss=20.915632981806993/20.91668191179633,train/test_acc=0.6875/0.5,\n",
      "epoch=226,loss=20.914530277252197/20.915632981806993,train/test_acc=0.6875/0.5,\n",
      "epoch=227,loss=20.91336802393198/20.914530277252197,train/test_acc=0.6875/0.5,\n",
      "epoch=228,loss=20.912142783403397/20.91336802393198,train/test_acc=0.6875/0.5,\n",
      "epoch=229,loss=20.910848036408424/20.912142783403397,train/test_acc=0.6875/0.5,\n",
      "epoch=230,loss=20.90947798267007/20.910848036408424,train/test_acc=0.6875/0.5,\n",
      "epoch=231,loss=20.90802840143442/20.90947798267007,train/test_acc=0.6875/0.5,\n",
      "epoch=232,loss=20.90649250894785/20.90802840143442,train/test_acc=0.6875/0.5,\n",
      "epoch=233,loss=20.904865954071283/20.90649250894785,train/test_acc=0.6875/0.5,\n",
      "epoch=234,loss=20.903141252696514/20.904865954071283,train/test_acc=0.6875/0.5,\n",
      "epoch=235,loss=20.901316050440073/20.903141252696514,train/test_acc=0.6875/0.5,\n",
      "epoch=236,loss=20.89938711374998/20.901316050440073,train/test_acc=0.6875/0.5,\n",
      "epoch=237,loss=20.897354025393724/20.89938711374998,train/test_acc=0.6875/0.55,\n",
      "epoch=238,loss=20.89521949738264/20.897354025393724,train/test_acc=0.6875/0.55,\n",
      "epoch=239,loss=20.892992325127125/20.89521949738264,train/test_acc=0.6875/0.55,\n",
      "epoch=240,loss=20.89068291336298/20.892992325127125,train/test_acc=0.6875/0.55,\n",
      "epoch=241,loss=20.888312734663486/20.89068291336298,train/test_acc=0.6875/0.55,\n",
      "epoch=242,loss=20.885906130075455/20.888312734663486,train/test_acc=0.6875/0.55,\n",
      "epoch=243,loss=20.88349423930049/20.885906130075455,train/test_acc=0.6875/0.55,\n",
      "epoch=244,loss=20.881111830472946/20.88349423930049,train/test_acc=0.6875/0.55,\n",
      "epoch=245,loss=20.878791518509388/20.881111830472946,train/test_acc=0.6875/0.55,\n",
      "epoch=246,loss=20.876561537384987/20.878791518509388,train/test_acc=0.6875/0.55,\n",
      "epoch=247,loss=20.874439544975758/20.876561537384987,train/test_acc=0.6875/0.55,\n",
      "epoch=248,loss=20.872429724782705/20.874439544975758,train/test_acc=0.6875/0.55,\n",
      "epoch=249,loss=20.87051770836115/20.872429724782705,train/test_acc=0.6875/0.55,\n",
      "epoch=250,loss=20.868679523468018/20.87051770836115,train/test_acc=0.6875/0.55,\n",
      "epoch=251,loss=20.86687583848834/20.868679523468018,train/test_acc=0.6875/0.55,\n",
      "epoch=252,loss=20.86506601795554/20.86687583848834,train/test_acc=0.6875/0.55,\n",
      "epoch=253,loss=20.86320350319147/20.86506601795554,train/test_acc=0.6875/0.55,\n",
      "epoch=254,loss=20.86123986542225/20.86320350319147,train/test_acc=0.6875/0.55,\n",
      "epoch=255,loss=20.859124451875687/20.86123986542225,train/test_acc=0.6875/0.55,\n",
      "epoch=256,loss=20.856801319867373/20.859124451875687,train/test_acc=0.6875/0.55,\n",
      "epoch=257,loss=20.854208786040545/20.856801319867373,train/test_acc=0.6875/0.55,\n",
      "epoch=258,loss=20.8512693233788/20.854208786040545,train/test_acc=0.6875/0.55,\n",
      "epoch=259,loss=20.84788755327463/20.8512693233788,train/test_acc=0.6875/0.55,\n",
      "epoch=260,loss=20.843936428427696/20.84788755327463,train/test_acc=0.6875/0.55,\n",
      "epoch=261,loss=20.83924487233162/20.843936428427696,train/test_acc=0.6875/0.55,\n",
      "epoch=262,loss=20.83356314152479/20.83924487233162,train/test_acc=0.6875/0.55,\n",
      "epoch=263,loss=20.82651612535119/20.83356314152479,train/test_acc=0.6875/0.55,\n",
      "epoch=264,loss=20.81748131290078/20.82651612535119,train/test_acc=0.6875/0.6,\n",
      "epoch=265,loss=20.805349998176098/20.81748131290078,train/test_acc=0.6875/0.6,\n",
      "epoch=266,loss=20.788003467023373/20.805349998176098,train/test_acc=0.6875/0.6,\n",
      "epoch=267,loss=20.76104797050357/20.788003467023373,train/test_acc=0.7/0.6,\n",
      "epoch=268,loss=20.713559690862894/20.76104797050357,train/test_acc=0.7/0.6,\n",
      "epoch=269,loss=20.612184286117554/20.713559690862894,train/test_acc=0.7/0.6,\n",
      "epoch=270,loss=20.432235930114985/20.612184286117554,train/test_acc=0.7/0.6,\n",
      "epoch=271,loss=20.30306652933359/20.432235930114985,train/test_acc=0.7/0.6,\n",
      "epoch=272,loss=20.214016653597355/20.30306652933359,train/test_acc=0.7125/0.55,\n",
      "epoch=273,loss=20.155194632709026/20.214016653597355,train/test_acc=0.7125/0.55,\n",
      "epoch=274,loss=20.03828751668334/20.155194632709026,train/test_acc=0.725/0.55,\n",
      "epoch=275,loss=19.75199408084154/20.03828751668334,train/test_acc=0.725/0.55,\n",
      "epoch=276,loss=19.296454768627882/19.75199408084154,train/test_acc=0.725/0.55,\n",
      "epoch=277,loss=19.115361005067825/19.296454768627882,train/test_acc=0.725/0.6,\n",
      "epoch=278,loss=19.01773739233613/19.115361005067825,train/test_acc=0.725/0.6,\n",
      "epoch=279,loss=18.86162466928363/19.01773739233613,train/test_acc=0.7375/0.6,\n",
      "epoch=280,loss=18.74152446910739/18.86162466928363,train/test_acc=0.7375/0.6,\n",
      "epoch=281,loss=18.596898902207613/18.74152446910739,train/test_acc=0.7375/0.6,\n",
      "epoch=282,loss=18.424241695553064/18.596898902207613,train/test_acc=0.7375/0.6,\n",
      "epoch=283,loss=18.325322315096855/18.424241695553064,train/test_acc=0.7375/0.6,\n",
      "epoch=284,loss=18.281879104673862/18.325322315096855,train/test_acc=0.7375/0.6,\n",
      "epoch=285,loss=18.262189500033855/18.281879104673862,train/test_acc=0.7375/0.6,\n",
      "epoch=286,loss=18.249705214053392/18.262189500033855,train/test_acc=0.7375/0.6,\n",
      "epoch=287,loss=18.240626864135265/18.249705214053392,train/test_acc=0.7375/0.6,\n",
      "epoch=288,loss=18.233485970646143/18.240626864135265,train/test_acc=0.7375/0.6,\n",
      "epoch=289,loss=18.22753018885851/18.233485970646143,train/test_acc=0.7375/0.6,\n",
      "epoch=290,loss=18.22231914103031/18.22753018885851,train/test_acc=0.7375/0.6,\n",
      "epoch=291,loss=18.217567313462496/18.22231914103031,train/test_acc=0.7375/0.6,\n",
      "epoch=292,loss=18.213072579354048/18.217567313462496,train/test_acc=0.7375/0.6,\n",
      "epoch=293,loss=18.208677113056183/18.213072579354048,train/test_acc=0.7375/0.6,\n",
      "epoch=294,loss=18.20424387231469/18.208677113056183,train/test_acc=0.7375/0.6,\n",
      "epoch=295,loss=18.199636671692133/18.20424387231469,train/test_acc=0.7375/0.6,\n",
      "epoch=296,loss=18.19470750167966/18.199636671692133,train/test_acc=0.7375/0.6,\n",
      "epoch=297,loss=18.189272217452526/18.19470750167966,train/test_acc=0.7375/0.6,\n",
      "epoch=298,loss=18.18309047818184/18.189272217452526,train/test_acc=0.7375/0.6,\n",
      "epoch=299,loss=18.175817251205444/18.18309047818184,train/test_acc=0.7375/0.6,\n",
      "acc:  0.71\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    w1 = torch.randn(784, 200, requires_grad=True)\n",
    "    w2 = torch.randn(200, 10, requires_grad=True)\n",
    "    b1 = torch.zeros(1, 200,requires_grad=True)\n",
    "    b2 = torch.zeros(1, 10, requires_grad=True)\n",
    "    \n",
    "    w1, w2, b1, b2 = train_model(train_data, train_label, w1, w2,b1,b2)\n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(0,100):\n",
    "        feature = get_feature(train_data[i])\n",
    "        y = model(feature, w1, w2,b1,b2)\n",
    "        gt = train_label[i]\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        if pred == gt:\n",
    "            correct += 1\n",
    "    \n",
    "    print(\"acc: \", correct / float(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3])\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "res = model(train_data[7].view(1,784), w1,w2,b1,b2)\n",
    "pred = torch.argmax(res, dim=1)\n",
    "print(pred)\n",
    "print(train_label[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndiAJwg4k8b9rUC9l53pqpQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[7].detach().numpy().reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(image_train, train_label, image_test, test_label, w1, w2, b1, b2, lrt=0.01):    \n",
    "#     iter_nums = 1000\n",
    "#     train_size = image_train.shape[0]\n",
    "# #     batch_size = 10\n",
    "\n",
    "#     train_loss_list = []\n",
    "#     train_acc_list = []\n",
    "#     test_acc_list = []\n",
    "    \n",
    "#     one_hot_train = onehot(train_label)\n",
    "#     one_hot_test = onehot(test_label)\n",
    "\n",
    "    \n",
    "#     for i in range(iter_nums):\n",
    "#         loss_last_epoch = 0\n",
    "#         train_acc_epoch = 0\n",
    "#         test_acc_epoch = 0\n",
    "        \n",
    "#         batch_mask = np.random.choice(100, 10)\n",
    "#         train_epoch = image_train[batch_mask]\n",
    "#         label_epoch = one_hot_train[batch_mask]\n",
    "\n",
    "# #         for idx, img in enumerate(image_train):\n",
    "#         y = predict(train_epoch, w1, b1, w2, b2)\n",
    "#     #         print(y)\n",
    "#         loss = torch.sum(0.5 * torch.mul((y - label_epoch), (y - label_epoch)))\n",
    "#         train_loss_list.append(loss)\n",
    "#         print('loss is ',loss.data.item())\n",
    "#             # 反向传播计算梯度\n",
    "#         loss.backward()\n",
    "#         w1.data.sub_(w1.grad.data * lrt)\n",
    "#         w2.data.sub_(w2.grad.data * lrt)\n",
    "#         b1.data.sub_(b1.grad.data * lrt)\n",
    "#         b2.data.sub_(b2.grad.data * lrt)\n",
    "            \n",
    "#         w1.grad.data.zero_()\n",
    "#         b1.grad.data.zero_()\n",
    "#         w2.grad.data.zero_()\n",
    "#         b2.grad.data.zero_()\n",
    "\n",
    "#         train_acc_epoch = accuracy(image_train, train_label, w1, b1, w2, b2)\n",
    "#         test_acc_epoch = accuracy(image_test, test_label, w1, b1, w2, b2)\n",
    "\n",
    "#         train_acc_list.append(train_acc_epoch)\n",
    "#         test_acc_list.append(test_acc_epoch)\n",
    "#         print('train acc, test acc  ' + str(test_acc_epoch) + ', ' + str(test_acc_epoch))\n",
    "# #         print('loss is ', loss_last_epoch / 10)\n",
    "        \n",
    "#     return w1, w2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output1 = predict(image_test, w1,b1,w2,b2)\n",
    "# print(output1)\n",
    "# y = torch.argmax(output1, dim=1)\n",
    "# gt = onehot(test_label)\n",
    "# # print(gt)\n",
    "# # cnt = torch.sum(y == test_label)\n",
    "# # print('cnt = ', cnt )\n",
    "# # print(image_test.shape[0])\n",
    "# # print(cnt.data.item() / image_test.shape[0])\n",
    "# # acc = accuracy(image_test, test_label, w1, b1, w2, b2)\n",
    "# loss = torch.sum(0.5 * (output1 - gt).mul(output1 - gt))\n",
    "# print(loss)\n",
    "# loss.backward()\n",
    "\n",
    "# # print(acc)\n",
    "# # print(loss)\n",
    "# print('w1 grad', sum(w1.grad))\n",
    "# print('shape of grad w1',w1.grad.shape)\n",
    "# print('w1 size',b1.shape)\n",
    "# # print(output1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_AI_CV",
   "language": "python",
   "name": "cv_ml_kr_skl_torch_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
