{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import  nn\n",
    "from itertools import product\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('F:\\CV_core_course\\week4')\n",
    "from mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdb():\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature,layers):\n",
    "    y=-1\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    B = len(feature)\n",
    "    fea=torch.tensor(feature).view(B,1,28,28).float()\n",
    "    fea= torch.relu(layers[0](fea))\n",
    "    # 完成lenet前向计算部分\n",
    "    fea= layers[1](fea) # maxpooling\n",
    "    fea= torch.relu(layers[2](fea)) # conv3\n",
    "    fea= layers[3](fea) # maxpooling\n",
    "#     print(fea.shape)\n",
    "#     pdb()\n",
    "#     print(fea.shape)\n",
    "#     pdb()\n",
    "    fea= layers[4](fea) # conv5\n",
    "#     print(fea.shape)\n",
    "#     pdb()\n",
    "    fea = fea.view(B, fea.shape[1])\n",
    "#     print(fea.shape)\n",
    "#     pdb()\n",
    "    fea= torch.relu(layers[5](fea)) # 120 -> 84\n",
    "    #output= torch.relu(layers[6](fea))\n",
    "    output= torch.sigmoid(layers[6](fea)) # 84 -> 10\n",
    "    y=output\n",
    "    #pdb()\n",
    "    #y=torch.softmax(output,1)\n",
    "    #y = 1.0/(1.0+torch.exp(-1.*h))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(image_data,image_label,layers,start_i,end_i):\n",
    "    correct=0\n",
    "    for i in range(start_i,end_i):\n",
    "        y = model(image_data[i:i+1],layers)\n",
    "        gt = image_label[i]\n",
    "        pred = torch.argmax(y).item()\n",
    "        if gt==pred:\n",
    "            correct+=1\n",
    "    #print(\"acc=%s\"%(float(correct/20.0)))\n",
    "    return  float(correct/float(end_i-start_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(image_data,image_label,layers,lr):\n",
    "    loss_value_before=1000000000000000.\n",
    "    loss_value=10000000000000.\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    for epoch in range(0,200):\n",
    "        loss_value_before=loss_value\n",
    "        loss_value=0\n",
    "        #print(image_label[i])\n",
    "        B = len(image_data)\n",
    "        B = 80\n",
    "        y = model(image_data[0:B],layers)\n",
    "        gt=torch.tensor(image_label[0:B]).view(B,1)\n",
    "        # get one_hot\n",
    "        gt_vector = torch.zeros(B,10).scatter_(1,gt,1)\n",
    "        #pdb.set_trace()\n",
    "        # 关心所有值\n",
    "        loss = torch.sum((y-gt_vector).mul(y-gt_vector))\n",
    "        # 优化loss，正样本接近1，负样本远离1\n",
    "        #loss1 = (y-1.0).mul(y-1.0)\n",
    "        #loss = loss1[0,gt]+torch.sum(1.0/(loss1[0,0:gt]))+torch.sum(1.0/(loss1[0,gt:-1]))\n",
    "        loss_value += loss.data.item()\n",
    "        # 更新公式\n",
    "        # w  = w - (y-y1)*x*lr\n",
    "        loss.backward()\n",
    "        for i in [0,2,4,5,6]: \n",
    "            layers[i].weight.data.sub_(layers[i].weight.grad.data*lr)\n",
    "            layers[i].weight.grad.data.zero_()\n",
    "            layers[i].bias.data.sub_(layers[i].bias.grad.data*lr)\n",
    "            layers[i].bias.grad.data.zero_()\n",
    "        train_acc=get_acc(image_data,image_label,layers,0,80)\n",
    "        test_acc =get_acc(image_data,image_label,layers,80,100)\n",
    "        print(\"epoch=%s,loss=%s/%s,train/test_acc:%s/%s\"%(epoch,loss_value,loss_value_before,train_acc,test_acc))\n",
    "    return layers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始的未训练时模型的acc=0.0\n",
      "> <ipython-input-16-904dc1ca3945>(4)pdb()\n",
      "-> pass\n",
      "(Pdb) c\n",
      "epoch=0,loss=248.6334686279297/10000000000000.0,train/test_acc:0.075/0.05\n",
      "epoch=1,loss=111.10456085205078/248.6334686279297,train/test_acc:0.0875/0.1\n",
      "epoch=2,loss=81.82669067382812/111.10456085205078,train/test_acc:0.125/0.1\n",
      "epoch=3,loss=75.88917541503906/81.82669067382812,train/test_acc:0.2/0.1\n",
      "epoch=4,loss=73.27644348144531/75.88917541503906,train/test_acc:0.2125/0.2\n",
      "epoch=5,loss=71.21151733398438/73.27644348144531,train/test_acc:0.2375/0.2\n",
      "epoch=6,loss=69.34847259521484/71.21151733398438,train/test_acc:0.2875/0.25\n",
      "epoch=7,loss=67.5311508178711/69.34847259521484,train/test_acc:0.325/0.25\n",
      "epoch=8,loss=65.76844787597656/67.5311508178711,train/test_acc:0.325/0.3\n",
      "epoch=9,loss=63.97997283935547/65.76844787597656,train/test_acc:0.35/0.3\n",
      "epoch=10,loss=62.186859130859375/63.97997283935547,train/test_acc:0.3875/0.3\n",
      "epoch=11,loss=60.31974411010742/62.186859130859375,train/test_acc:0.4125/0.35\n",
      "epoch=12,loss=58.53693389892578/60.31974411010742,train/test_acc:0.4375/0.4\n",
      "epoch=13,loss=56.975364685058594/58.53693389892578,train/test_acc:0.4875/0.4\n",
      "epoch=14,loss=55.55242919921875/56.975364685058594,train/test_acc:0.5125/0.4\n",
      "epoch=15,loss=54.22618103027344/55.55242919921875,train/test_acc:0.525/0.4\n",
      "epoch=16,loss=52.934234619140625/54.22618103027344,train/test_acc:0.5375/0.4\n",
      "epoch=17,loss=51.647804260253906/52.934234619140625,train/test_acc:0.5625/0.45\n",
      "epoch=18,loss=50.39079666137695/51.647804260253906,train/test_acc:0.6/0.5\n",
      "epoch=19,loss=49.125614166259766/50.39079666137695,train/test_acc:0.6125/0.5\n",
      "epoch=20,loss=47.877105712890625/49.125614166259766,train/test_acc:0.625/0.55\n",
      "epoch=21,loss=46.6357421875/47.877105712890625,train/test_acc:0.625/0.55\n",
      "epoch=22,loss=45.424896240234375/46.6357421875,train/test_acc:0.6625/0.55\n",
      "epoch=23,loss=44.26525115966797/45.424896240234375,train/test_acc:0.675/0.55\n",
      "epoch=24,loss=43.114871978759766/44.26525115966797,train/test_acc:0.675/0.6\n",
      "epoch=25,loss=41.98258972167969/43.114871978759766,train/test_acc:0.675/0.6\n",
      "epoch=26,loss=40.89131164550781/41.98258972167969,train/test_acc:0.7/0.6\n",
      "epoch=27,loss=39.83212661743164/40.89131164550781,train/test_acc:0.7/0.6\n",
      "epoch=28,loss=38.7784423828125/39.83212661743164,train/test_acc:0.7125/0.6\n",
      "epoch=29,loss=37.75408172607422/38.7784423828125,train/test_acc:0.725/0.6\n",
      "epoch=30,loss=36.75746154785156/37.75408172607422,train/test_acc:0.75/0.6\n",
      "epoch=31,loss=35.790863037109375/36.75746154785156,train/test_acc:0.75/0.55\n",
      "epoch=32,loss=34.844356536865234/35.790863037109375,train/test_acc:0.75/0.55\n",
      "epoch=33,loss=33.93196487426758/34.844356536865234,train/test_acc:0.7625/0.6\n",
      "epoch=34,loss=33.03219985961914/33.93196487426758,train/test_acc:0.7875/0.6\n",
      "epoch=35,loss=32.159027099609375/33.03219985961914,train/test_acc:0.7875/0.6\n",
      "epoch=36,loss=31.31433868408203/32.159027099609375,train/test_acc:0.7875/0.6\n",
      "epoch=37,loss=30.48870849609375/31.31433868408203,train/test_acc:0.8/0.6\n",
      "epoch=38,loss=29.686655044555664/30.48870849609375,train/test_acc:0.8/0.65\n",
      "epoch=39,loss=28.90851593017578/29.686655044555664,train/test_acc:0.8125/0.65\n",
      "epoch=40,loss=28.157026290893555/28.90851593017578,train/test_acc:0.825/0.65\n",
      "epoch=41,loss=27.42255401611328/28.157026290893555,train/test_acc:0.8375/0.65\n",
      "epoch=42,loss=26.719999313354492/27.42255401611328,train/test_acc:0.8375/0.65\n",
      "epoch=43,loss=26.032419204711914/26.719999313354492,train/test_acc:0.85/0.65\n",
      "epoch=44,loss=25.370573043823242/26.032419204711914,train/test_acc:0.85/0.65\n",
      "epoch=45,loss=24.728185653686523/25.370573043823242,train/test_acc:0.85/0.65\n",
      "epoch=46,loss=24.11608123779297/24.728185653686523,train/test_acc:0.85/0.65\n",
      "epoch=47,loss=23.537330627441406/24.11608123779297,train/test_acc:0.8625/0.65\n",
      "epoch=48,loss=22.987659454345703/23.537330627441406,train/test_acc:0.8625/0.65\n",
      "epoch=49,loss=22.462310791015625/22.987659454345703,train/test_acc:0.8625/0.65\n",
      "epoch=50,loss=21.957592010498047/22.462310791015625,train/test_acc:0.8625/0.65\n",
      "epoch=51,loss=21.476181030273438/21.957592010498047,train/test_acc:0.8625/0.65\n",
      "epoch=52,loss=21.00627326965332/21.476181030273438,train/test_acc:0.8875/0.65\n",
      "epoch=53,loss=20.555252075195312/21.00627326965332,train/test_acc:0.8875/0.65\n",
      "epoch=54,loss=20.116985321044922/20.555252075195312,train/test_acc:0.8875/0.65\n",
      "epoch=55,loss=19.696575164794922/20.116985321044922,train/test_acc:0.8875/0.65\n",
      "epoch=56,loss=19.28380012512207/19.696575164794922,train/test_acc:0.8875/0.65\n",
      "epoch=57,loss=18.890146255493164/19.28380012512207,train/test_acc:0.8875/0.65\n",
      "epoch=58,loss=18.512311935424805/18.890146255493164,train/test_acc:0.8875/0.65\n",
      "epoch=59,loss=18.152427673339844/18.512311935424805,train/test_acc:0.8875/0.65\n",
      "epoch=60,loss=17.79825782775879/18.152427673339844,train/test_acc:0.8875/0.7\n",
      "epoch=61,loss=17.45169448852539/17.79825782775879,train/test_acc:0.8875/0.65\n",
      "epoch=62,loss=17.11557388305664/17.45169448852539,train/test_acc:0.8875/0.7\n",
      "epoch=63,loss=16.786949157714844/17.11557388305664,train/test_acc:0.8875/0.7\n",
      "epoch=64,loss=16.468807220458984/16.786949157714844,train/test_acc:0.8875/0.7\n",
      "epoch=65,loss=16.155363082885742/16.468807220458984,train/test_acc:0.8875/0.7\n",
      "epoch=66,loss=15.851555824279785/16.155363082885742,train/test_acc:0.8875/0.7\n",
      "epoch=67,loss=15.54624080657959/15.851555824279785,train/test_acc:0.9125/0.7\n",
      "epoch=68,loss=15.24349594116211/15.54624080657959,train/test_acc:0.925/0.7\n",
      "epoch=69,loss=14.945223808288574/15.24349594116211,train/test_acc:0.925/0.7\n",
      "epoch=70,loss=14.65318489074707/14.945223808288574,train/test_acc:0.925/0.7\n",
      "epoch=71,loss=14.36557388305664/14.65318489074707,train/test_acc:0.925/0.7\n",
      "epoch=72,loss=14.084351539611816/14.36557388305664,train/test_acc:0.925/0.7\n",
      "epoch=73,loss=13.81387710571289/14.084351539611816,train/test_acc:0.925/0.7\n",
      "epoch=74,loss=13.54786205291748/13.81387710571289,train/test_acc:0.925/0.7\n",
      "epoch=75,loss=13.289233207702637/13.54786205291748,train/test_acc:0.925/0.7\n",
      "epoch=76,loss=13.038595199584961/13.289233207702637,train/test_acc:0.925/0.7\n",
      "epoch=77,loss=12.790724754333496/13.038595199584961,train/test_acc:0.925/0.7\n",
      "epoch=78,loss=12.554569244384766/12.790724754333496,train/test_acc:0.925/0.7\n",
      "epoch=79,loss=12.324731826782227/12.554569244384766,train/test_acc:0.925/0.7\n",
      "epoch=80,loss=12.09896183013916/12.324731826782227,train/test_acc:0.925/0.7\n",
      "epoch=81,loss=11.884678840637207/12.09896183013916,train/test_acc:0.925/0.7\n",
      "epoch=82,loss=11.676857948303223/11.884678840637207,train/test_acc:0.925/0.7\n",
      "epoch=83,loss=11.479528427124023/11.676857948303223,train/test_acc:0.925/0.7\n",
      "epoch=84,loss=11.286709785461426/11.479528427124023,train/test_acc:0.925/0.7\n",
      "epoch=85,loss=11.102205276489258/11.286709785461426,train/test_acc:0.9375/0.7\n",
      "epoch=86,loss=10.921797752380371/11.102205276489258,train/test_acc:0.9375/0.7\n",
      "epoch=87,loss=10.747891426086426/10.921797752380371,train/test_acc:0.9375/0.7\n",
      "epoch=88,loss=10.578283309936523/10.747891426086426,train/test_acc:0.9375/0.75\n",
      "epoch=89,loss=10.416147232055664/10.578283309936523,train/test_acc:0.9375/0.75\n",
      "epoch=90,loss=10.25384521484375/10.416147232055664,train/test_acc:0.9375/0.75\n",
      "epoch=91,loss=10.09998607635498/10.25384521484375,train/test_acc:0.9375/0.75\n",
      "epoch=92,loss=9.95058536529541/10.09998607635498,train/test_acc:0.9375/0.8\n",
      "epoch=93,loss=9.802498817443848/9.95058536529541,train/test_acc:0.9375/0.85\n",
      "epoch=94,loss=9.664534568786621/9.802498817443848,train/test_acc:0.9375/0.85\n",
      "epoch=95,loss=9.524460792541504/9.664534568786621,train/test_acc:0.9375/0.85\n",
      "epoch=96,loss=9.389949798583984/9.524460792541504,train/test_acc:0.9375/0.85\n",
      "epoch=97,loss=9.258344650268555/9.389949798583984,train/test_acc:0.9375/0.85\n",
      "epoch=98,loss=9.126697540283203/9.258344650268555,train/test_acc:0.9375/0.85\n",
      "epoch=99,loss=8.995726585388184/9.126697540283203,train/test_acc:0.9375/0.85\n",
      "epoch=100,loss=8.86723804473877/8.995726585388184,train/test_acc:0.95/0.85\n",
      "epoch=101,loss=8.740252494812012/8.86723804473877,train/test_acc:0.95/0.85\n",
      "epoch=102,loss=8.613065719604492/8.740252494812012,train/test_acc:0.95/0.85\n",
      "epoch=103,loss=8.485943794250488/8.613065719604492,train/test_acc:0.95/0.85\n",
      "epoch=104,loss=8.358396530151367/8.485943794250488,train/test_acc:0.95/0.85\n",
      "epoch=105,loss=8.23210620880127/8.358396530151367,train/test_acc:0.95/0.85\n",
      "epoch=106,loss=8.106218338012695/8.23210620880127,train/test_acc:0.95/0.85\n",
      "epoch=107,loss=7.980175018310547/8.106218338012695,train/test_acc:0.95/0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=108,loss=7.857048034667969/7.980175018310547,train/test_acc:0.95/0.85\n",
      "epoch=109,loss=7.732974529266357/7.857048034667969,train/test_acc:0.95/0.85\n",
      "epoch=110,loss=7.614157199859619/7.732974529266357,train/test_acc:0.95/0.85\n",
      "epoch=111,loss=7.496658802032471/7.614157199859619,train/test_acc:0.95/0.85\n",
      "epoch=112,loss=7.384012222290039/7.496658802032471,train/test_acc:0.95/0.85\n",
      "epoch=113,loss=7.274693012237549/7.384012222290039,train/test_acc:0.95/0.85\n",
      "epoch=114,loss=7.170454025268555/7.274693012237549,train/test_acc:0.95/0.85\n",
      "epoch=115,loss=7.072883129119873/7.170454025268555,train/test_acc:0.95/0.85\n",
      "epoch=116,loss=6.981021881103516/7.072883129119873,train/test_acc:0.95/0.85\n",
      "epoch=117,loss=6.891683101654053/6.981021881103516,train/test_acc:0.95/0.9\n",
      "epoch=118,loss=6.809320449829102/6.891683101654053,train/test_acc:0.95/0.85\n",
      "epoch=119,loss=6.729002475738525/6.809320449829102,train/test_acc:0.95/0.9\n",
      "epoch=120,loss=6.652617454528809/6.729002475738525,train/test_acc:0.95/0.9\n",
      "epoch=121,loss=6.58021354675293/6.652617454528809,train/test_acc:0.95/0.9\n",
      "epoch=122,loss=6.51122522354126/6.58021354675293,train/test_acc:0.95/0.9\n",
      "epoch=123,loss=6.445896625518799/6.51122522354126,train/test_acc:0.95/0.9\n",
      "epoch=124,loss=6.3833327293396/6.445896625518799,train/test_acc:0.95/0.9\n",
      "epoch=125,loss=6.323085308074951/6.3833327293396,train/test_acc:0.95/0.9\n",
      "epoch=126,loss=6.266535758972168/6.323085308074951,train/test_acc:0.95/0.9\n",
      "epoch=127,loss=6.212541103363037/6.266535758972168,train/test_acc:0.95/0.9\n",
      "epoch=128,loss=6.159687519073486/6.212541103363037,train/test_acc:0.95/0.9\n",
      "epoch=129,loss=6.110146522521973/6.159687519073486,train/test_acc:0.95/0.9\n",
      "epoch=130,loss=6.062184810638428/6.110146522521973,train/test_acc:0.95/0.9\n",
      "epoch=131,loss=6.015496730804443/6.062184810638428,train/test_acc:0.95/0.9\n",
      "epoch=132,loss=5.970980167388916/6.015496730804443,train/test_acc:0.95/0.9\n",
      "epoch=133,loss=5.928527355194092/5.970980167388916,train/test_acc:0.95/0.9\n",
      "epoch=134,loss=5.886770248413086/5.928527355194092,train/test_acc:0.95/0.9\n",
      "epoch=135,loss=5.847078323364258/5.886770248413086,train/test_acc:0.95/0.9\n",
      "epoch=136,loss=5.8075761795043945/5.847078323364258,train/test_acc:0.95/0.9\n",
      "epoch=137,loss=5.770382881164551/5.8075761795043945,train/test_acc:0.95/0.9\n",
      "epoch=138,loss=5.734410285949707/5.770382881164551,train/test_acc:0.95/0.9\n",
      "epoch=139,loss=5.699586391448975/5.734410285949707,train/test_acc:0.95/0.9\n",
      "epoch=140,loss=5.666317939758301/5.699586391448975,train/test_acc:0.95/0.9\n",
      "epoch=141,loss=5.6337890625/5.666317939758301,train/test_acc:0.95/0.9\n",
      "epoch=142,loss=5.602593421936035/5.6337890625,train/test_acc:0.95/0.9\n",
      "epoch=143,loss=5.572747707366943/5.602593421936035,train/test_acc:0.95/0.9\n",
      "epoch=144,loss=5.543598175048828/5.572747707366943,train/test_acc:0.95/0.9\n",
      "epoch=145,loss=5.515738487243652/5.543598175048828,train/test_acc:0.95/0.9\n",
      "epoch=146,loss=5.488190174102783/5.515738487243652,train/test_acc:0.95/0.9\n",
      "epoch=147,loss=5.461783409118652/5.488190174102783,train/test_acc:0.95/0.9\n",
      "epoch=148,loss=5.436468124389648/5.461783409118652,train/test_acc:0.95/0.9\n",
      "epoch=149,loss=5.411772727966309/5.436468124389648,train/test_acc:0.95/0.9\n",
      "epoch=150,loss=5.3879241943359375/5.411772727966309,train/test_acc:0.95/0.9\n",
      "epoch=151,loss=5.364268779754639/5.3879241943359375,train/test_acc:0.95/0.9\n",
      "epoch=152,loss=5.341668605804443/5.364268779754639,train/test_acc:0.95/0.9\n",
      "epoch=153,loss=5.319766521453857/5.341668605804443,train/test_acc:0.95/0.9\n",
      "epoch=154,loss=5.298422813415527/5.319766521453857,train/test_acc:0.95/0.9\n",
      "epoch=155,loss=5.277713775634766/5.298422813415527,train/test_acc:0.95/0.9\n",
      "epoch=156,loss=5.2574262619018555/5.277713775634766,train/test_acc:0.95/0.9\n",
      "epoch=157,loss=5.237879753112793/5.2574262619018555,train/test_acc:0.95/0.9\n",
      "epoch=158,loss=5.21845006942749/5.237879753112793,train/test_acc:0.95/0.9\n",
      "epoch=159,loss=5.19984769821167/5.21845006942749,train/test_acc:0.95/0.9\n",
      "epoch=160,loss=5.181744575500488/5.19984769821167,train/test_acc:0.95/0.9\n",
      "epoch=161,loss=5.163849353790283/5.181744575500488,train/test_acc:0.95/0.9\n",
      "epoch=162,loss=5.146491050720215/5.163849353790283,train/test_acc:0.95/0.9\n",
      "epoch=163,loss=5.12992525100708/5.146491050720215,train/test_acc:0.95/0.9\n",
      "epoch=164,loss=5.113387584686279/5.12992525100708,train/test_acc:0.95/0.9\n",
      "epoch=165,loss=5.097224235534668/5.113387584686279,train/test_acc:0.95/0.9\n",
      "epoch=166,loss=5.081363201141357/5.097224235534668,train/test_acc:0.95/0.9\n",
      "epoch=167,loss=5.066193103790283/5.081363201141357,train/test_acc:0.95/0.9\n",
      "epoch=168,loss=5.051091194152832/5.066193103790283,train/test_acc:0.95/0.9\n",
      "epoch=169,loss=5.036346435546875/5.051091194152832,train/test_acc:0.95/0.9\n",
      "epoch=170,loss=5.022110462188721/5.036346435546875,train/test_acc:0.95/0.9\n",
      "epoch=171,loss=5.008041858673096/5.022110462188721,train/test_acc:0.95/0.9\n",
      "epoch=172,loss=4.9941229820251465/5.008041858673096,train/test_acc:0.95/0.9\n",
      "epoch=173,loss=4.980642318725586/4.9941229820251465,train/test_acc:0.95/0.9\n",
      "epoch=174,loss=4.967494010925293/4.980642318725586,train/test_acc:0.95/0.9\n",
      "epoch=175,loss=4.954455852508545/4.967494010925293,train/test_acc:0.95/0.9\n",
      "epoch=176,loss=4.941864967346191/4.954455852508545,train/test_acc:0.95/0.9\n",
      "epoch=177,loss=4.929264068603516/4.941864967346191,train/test_acc:0.95/0.9\n",
      "epoch=178,loss=4.9170427322387695/4.929264068603516,train/test_acc:0.95/0.9\n",
      "epoch=179,loss=4.905070781707764/4.9170427322387695,train/test_acc:0.95/0.9\n",
      "epoch=180,loss=4.893387794494629/4.905070781707764,train/test_acc:0.95/0.9\n",
      "epoch=181,loss=4.881822109222412/4.893387794494629,train/test_acc:0.95/0.9\n",
      "epoch=182,loss=4.870499610900879/4.881822109222412,train/test_acc:0.95/0.9\n",
      "epoch=183,loss=4.85941743850708/4.870499610900879,train/test_acc:0.95/0.9\n",
      "epoch=184,loss=4.848666191101074/4.85941743850708,train/test_acc:0.95/0.9\n",
      "epoch=185,loss=4.838132381439209/4.848666191101074,train/test_acc:0.95/0.9\n",
      "epoch=186,loss=4.827798843383789/4.838132381439209,train/test_acc:0.95/0.9\n",
      "epoch=187,loss=4.817433834075928/4.827798843383789,train/test_acc:0.95/0.9\n",
      "epoch=188,loss=4.8072285652160645/4.817433834075928,train/test_acc:0.95/0.9\n",
      "epoch=189,loss=4.797379970550537/4.8072285652160645,train/test_acc:0.95/0.9\n",
      "epoch=190,loss=4.787650108337402/4.797379970550537,train/test_acc:0.95/0.9\n",
      "epoch=191,loss=4.778165340423584/4.787650108337402,train/test_acc:0.95/0.9\n",
      "epoch=192,loss=4.7686686515808105/4.778165340423584,train/test_acc:0.95/0.9\n",
      "epoch=193,loss=4.7594404220581055/4.7686686515808105,train/test_acc:0.95/0.9\n",
      "epoch=194,loss=4.750284194946289/4.7594404220581055,train/test_acc:0.95/0.9\n",
      "epoch=195,loss=4.741421699523926/4.750284194946289,train/test_acc:0.95/0.9\n",
      "epoch=196,loss=4.732594966888428/4.741421699523926,train/test_acc:0.95/0.9\n",
      "epoch=197,loss=4.723902702331543/4.732594966888428,train/test_acc:0.95/0.9\n",
      "epoch=198,loss=4.715271949768066/4.723902702331543,train/test_acc:0.95/0.9\n",
      "epoch=199,loss=4.706977367401123/4.715271949768066,train/test_acc:0.95/0.9\n",
      "训练完成后模型的acc=0.9\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # 从输入中获取学习率\n",
    "    lr = float(0.00005)\n",
    "    layers=[]\n",
    "    '''\n",
    "    卷积层c1，通道数从1到6，因为mnist数据集的大小为28*28，所以padding=2\n",
    "    输出层神经元数量28*28*6，可训练参数((5*5)+1)*6，连接数((5*5)+1)*6*28*28=122304\n",
    "    '''\n",
    "    conv1= nn.Conv2d(1, 6, 5, stride=1, padding=2)\n",
    "    layers.append(conv1)\n",
    "    '''\n",
    "    Max池化层，无可训练参数，对特征图进行压缩，一方面使得特征图变小，简化网络计算复杂度，另一方面提取主要特征\n",
    "    ''' \n",
    "    pool2= nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    layers.append(pool2)\n",
    "    \n",
    "    '''\n",
    "    卷积层c3，通道数从6到16个，卷积核大小5 * 5，padding=0，提取更多的特征\n",
    "    '''\n",
    "    conv3= nn.Conv2d(6, 16, 5, stride=1, padding=0)\n",
    "    layers.append(conv3)\n",
    "    '''\n",
    "    Max池化层，无可训练参数，将10*10的feature map降采样到5*5\n",
    "    '''\n",
    "    pool4=nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    layers.append(pool4)\n",
    "    '''\n",
    "    卷积层c5，通道数从16到120\n",
    "    '''\n",
    "    conv5 = nn.Conv2d(16,120,kernel_size=5, stride=1, padding=0)\n",
    "    layers.append(conv5)\n",
    "    '''\n",
    "    全连接\n",
    "    '''\n",
    "    f6 = nn.Linear(120, 84)\n",
    "    layers.append(f6)\n",
    "    '''\n",
    "    输出全连接\n",
    "    '''\n",
    "    output=nn.Linear(84,10)\n",
    "    layers.append(output)\n",
    "    # 记载数据\n",
    "    # minst 2828 dataset 60000 samples\n",
    "    mndata = MNIST('F:\\\\CV_core_course\\\\week4\\\\mnist\\\\python-mnist\\\\data\\\\')\n",
    "    image_data_all, image_label_all = mndata.load_training()\n",
    "    image_data=image_data_all[0:100]\n",
    "    image_label=image_label_all[0:100]\n",
    "    # 使用未训练的模型处理数据\n",
    "    y = model(image_data,layers)\n",
    "    # 使用为训练得模型测试 \n",
    "    print(\"初始的未训练时模型的acc=%s\"%(get_acc(image_data,image_label,layers,80,100)))\n",
    "    pdb()\n",
    "    # 对模型进行训练：\n",
    "    train_model(image_data,image_label,layers,lr)\n",
    "    # 训练完成，对模型进行测试，给出测试结果：\n",
    "    print(\"训练完成后模型的acc=%s\"%(get_acc(image_data,image_label,layers,80,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('F:\\\\CV_core_course\\\\week4\\\\mnist\\\\python-mnist\\\\data\\\\')\n",
    "image_data_all, image_label_all = mndata.load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(image_data_all[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_AI_CV",
   "language": "python",
   "name": "cv_ml_kr_skl_torch_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
